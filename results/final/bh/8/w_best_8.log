cuda available with GPU: Tesla V100-PCIE-16GB
==========Load Seed==========
set_random_seed
0
==========Training Start==========
Training Graphs:  2491
Valid Graphs:  277
Test Graphs:  1187
============Loading pretrained weights to generate initialization============
============Creating new layers============
============Creating Model============
Training Graphs Batches:  78
Valid Graphs Batches:  9
Test Graphs Batches:  37
[0/299] timecost: 64.60, lr: 0.000030, Train: (LOSS: 0.2338, MAE: 0.2338, RMSE: 0.2810, R2: -0.1311), Valid: (LOSS: 0.2225, MAE: 0.2225, RMSE: 0.2570, R2: 0.0225), PNorm: 174.4518, GNorm: 0.9436
[1/299] timecost: 62.96, lr: 0.000030, Train: (LOSS: 0.2161, MAE: 0.2161, RMSE: 0.2607, R2: 0.0352), Valid: (LOSS: 0.2319, MAE: 0.2319, RMSE: 0.2673, R2: -0.0680), PNorm: 173.7673, GNorm: 1.0185
[2/299] timecost: 64.43, lr: 0.000030, Train: (LOSS: 0.2047, MAE: 0.2047, RMSE: 0.2485, R2: 0.1177), Valid: (LOSS: 0.2011, MAE: 0.2011, RMSE: 0.2531, R2: 0.0401), PNorm: 173.1711, GNorm: 0.4748
[3/299] timecost: 65.01, lr: 0.000030, Train: (LOSS: 0.1872, MAE: 0.1872, RMSE: 0.2328, R2: 0.2201), Valid: (LOSS: 0.1728, MAE: 0.1728, RMSE: 0.2144, R2: 0.3102), PNorm: 172.6981, GNorm: 1.0189
[4/299] timecost: 65.14, lr: 0.000030, Train: (LOSS: 0.1502, MAE: 0.1502, RMSE: 0.1963, R2: 0.4258), Valid: (LOSS: 0.1242, MAE: 0.1242, RMSE: 0.1682, R2: 0.5703), PNorm: 172.3070, GNorm: 2.7893
[5/299] timecost: 65.19, lr: 0.000030, Train: (LOSS: 0.1369, MAE: 0.1369, RMSE: 0.1831, R2: 0.5068), Valid: (LOSS: 0.1284, MAE: 0.1284, RMSE: 0.1794, R2: 0.5077), PNorm: 171.9501, GNorm: 2.1825
[6/299] timecost: 64.50, lr: 0.000030, Train: (LOSS: 0.1390, MAE: 0.1390, RMSE: 0.1886, R2: 0.4662), Valid: (LOSS: 0.1247, MAE: 0.1247, RMSE: 0.1671, R2: 0.5751), PNorm: 171.6083, GNorm: 1.4762
[7/299] timecost: 64.07, lr: 0.000030, Train: (LOSS: 0.1298, MAE: 0.1298, RMSE: 0.1775, R2: 0.5307), Valid: (LOSS: 0.1163, MAE: 0.1163, RMSE: 0.1612, R2: 0.6084), PNorm: 171.2772, GNorm: 4.3271
[8/299] timecost: 63.22, lr: 0.000030, Train: (LOSS: 0.1212, MAE: 0.1212, RMSE: 0.1703, R2: 0.5778), Valid: (LOSS: 0.1150, MAE: 0.1150, RMSE: 0.1579, R2: 0.6224), PNorm: 170.9543, GNorm: 1.5078
[9/299] timecost: 63.27, lr: 0.000030, Train: (LOSS: 0.1197, MAE: 0.1197, RMSE: 0.1693, R2: 0.5734), Valid: (LOSS: 0.1083, MAE: 0.1083, RMSE: 0.1548, R2: 0.6373), PNorm: 170.6431, GNorm: 2.6985
[10/299] timecost: 63.14, lr: 0.000030, Train: (LOSS: 0.1230, MAE: 0.1230, RMSE: 0.1727, R2: 0.5633), Valid: (LOSS: 0.1050, MAE: 0.1050, RMSE: 0.1494, R2: 0.6594), PNorm: 170.3404, GNorm: 1.9155
[11/299] timecost: 63.44, lr: 0.000030, Train: (LOSS: 0.1155, MAE: 0.1155, RMSE: 0.1653, R2: 0.5758), Valid: (LOSS: 0.1057, MAE: 0.1057, RMSE: 0.1533, R2: 0.6370), PNorm: 170.0427, GNorm: 4.1432
[12/299] timecost: 64.35, lr: 0.000030, Train: (LOSS: 0.1110, MAE: 0.1110, RMSE: 0.1595, R2: 0.6218), Valid: (LOSS: 0.1088, MAE: 0.1088, RMSE: 0.1569, R2: 0.6285), PNorm: 169.7518, GNorm: 1.7031
[13/299] timecost: 63.99, lr: 0.000030, Train: (LOSS: 0.1112, MAE: 0.1112, RMSE: 0.1607, R2: 0.6207), Valid: (LOSS: 0.1013, MAE: 0.1013, RMSE: 0.1481, R2: 0.6685), PNorm: 169.4657, GNorm: 2.2348
[14/299] timecost: 63.98, lr: 0.000030, Train: (LOSS: 0.1040, MAE: 0.1040, RMSE: 0.1522, R2: 0.6559), Valid: (LOSS: 0.0965, MAE: 0.0965, RMSE: 0.1429, R2: 0.6900), PNorm: 169.1836, GNorm: 2.3967
[15/299] timecost: 63.85, lr: 0.000030, Train: (LOSS: 0.1023, MAE: 0.1023, RMSE: 0.1492, R2: 0.6613), Valid: (LOSS: 0.0956, MAE: 0.0956, RMSE: 0.1386, R2: 0.7106), PNorm: 168.9056, GNorm: 1.7947
[16/299] timecost: 63.63, lr: 0.000030, Train: (LOSS: 0.1021, MAE: 0.1021, RMSE: 0.1491, R2: 0.6674), Valid: (LOSS: 0.0958, MAE: 0.0958, RMSE: 0.1372, R2: 0.7170), PNorm: 168.6317, GNorm: 3.7145
[17/299] timecost: 64.46, lr: 0.000030, Train: (LOSS: 0.1000, MAE: 0.1000, RMSE: 0.1469, R2: 0.6736), Valid: (LOSS: 0.1091, MAE: 0.1091, RMSE: 0.1600, R2: 0.6082), PNorm: 168.3631, GNorm: 1.8590
[18/299] timecost: 64.17, lr: 0.000030, Train: (LOSS: 0.1031, MAE: 0.1031, RMSE: 0.1505, R2: 0.6557), Valid: (LOSS: 0.0991, MAE: 0.0991, RMSE: 0.1454, R2: 0.6716), PNorm: 168.0987, GNorm: 3.9875
[19/299] timecost: 63.26, lr: 0.000030, Train: (LOSS: 0.0951, MAE: 0.0951, RMSE: 0.1406, R2: 0.6975), Valid: (LOSS: 0.0876, MAE: 0.0876, RMSE: 0.1300, R2: 0.7464), PNorm: 167.8375, GNorm: 2.4995
[20/299] timecost: 63.05, lr: 0.000030, Train: (LOSS: 0.0923, MAE: 0.0923, RMSE: 0.1362, R2: 0.7283), Valid: (LOSS: 0.0978, MAE: 0.0978, RMSE: 0.1434, R2: 0.6874), PNorm: 167.5817, GNorm: 2.3311
[21/299] timecost: 63.26, lr: 0.000030, Train: (LOSS: 0.0890, MAE: 0.0890, RMSE: 0.1333, R2: 0.7357), Valid: (LOSS: 0.0897, MAE: 0.0897, RMSE: 0.1266, R2: 0.7572), PNorm: 167.3282, GNorm: 3.9112
[22/299] timecost: 63.85, lr: 0.000030, Train: (LOSS: 0.0874, MAE: 0.0874, RMSE: 0.1293, R2: 0.7416), Valid: (LOSS: 0.0852, MAE: 0.0852, RMSE: 0.1221, R2: 0.7727), PNorm: 167.0793, GNorm: 1.7946
[23/299] timecost: 63.67, lr: 0.000030, Train: (LOSS: 0.0909, MAE: 0.0909, RMSE: 0.1363, R2: 0.7269), Valid: (LOSS: 0.0921, MAE: 0.0921, RMSE: 0.1326, R2: 0.7356), PNorm: 166.8335, GNorm: 1.8640
[24/299] timecost: 63.30, lr: 0.000030, Train: (LOSS: 0.0855, MAE: 0.0855, RMSE: 0.1266, R2: 0.7579), Valid: (LOSS: 0.0998, MAE: 0.0998, RMSE: 0.1342, R2: 0.7195), PNorm: 166.5915, GNorm: 2.1166
[25/299] timecost: 63.59, lr: 0.000030, Train: (LOSS: 0.0796, MAE: 0.0796, RMSE: 0.1178, R2: 0.7932), Valid: (LOSS: 0.0739, MAE: 0.0739, RMSE: 0.1075, R2: 0.8240), PNorm: 166.3531, GNorm: 1.3925
[26/299] timecost: 63.37, lr: 0.000030, Train: (LOSS: 0.0832, MAE: 0.0832, RMSE: 0.1243, R2: 0.7679), Valid: (LOSS: 0.0849, MAE: 0.0849, RMSE: 0.1193, R2: 0.7793), PNorm: 166.1180, GNorm: 4.5987
[27/299] timecost: 63.29, lr: 0.000030, Train: (LOSS: 0.0752, MAE: 0.0752, RMSE: 0.1120, R2: 0.8102), Valid: (LOSS: 0.0737, MAE: 0.0737, RMSE: 0.1088, R2: 0.8087), PNorm: 165.8865, GNorm: 1.6597
[28/299] timecost: 63.56, lr: 0.000030, Train: (LOSS: 0.0764, MAE: 0.0764, RMSE: 0.1156, R2: 0.7916), Valid: (LOSS: 0.0867, MAE: 0.0867, RMSE: 0.1294, R2: 0.7352), PNorm: 165.6577, GNorm: 1.8359
[29/299] timecost: 63.65, lr: 0.000030, Train: (LOSS: 0.0730, MAE: 0.0730, RMSE: 0.1089, R2: 0.8157), Valid: (LOSS: 0.0682, MAE: 0.0682, RMSE: 0.1021, R2: 0.8358), PNorm: 165.4323, GNorm: 3.0635
[30/299] timecost: 63.57, lr: 0.000030, Train: (LOSS: 0.0708, MAE: 0.0708, RMSE: 0.1084, R2: 0.8211), Valid: (LOSS: 0.0711, MAE: 0.0711, RMSE: 0.1060, R2: 0.8275), PNorm: 165.2090, GNorm: 1.9683
[31/299] timecost: 63.14, lr: 0.000030, Train: (LOSS: 0.0664, MAE: 0.0664, RMSE: 0.1026, R2: 0.8392), Valid: (LOSS: 0.0724, MAE: 0.0724, RMSE: 0.1106, R2: 0.8081), PNorm: 164.9883, GNorm: 1.1621
[32/299] timecost: 64.58, lr: 0.000030, Train: (LOSS: 0.0662, MAE: 0.0662, RMSE: 0.1034, R2: 0.8282), Valid: (LOSS: 0.0652, MAE: 0.0652, RMSE: 0.0962, R2: 0.8560), PNorm: 164.7703, GNorm: 1.1329
[33/299] timecost: 63.05, lr: 0.000030, Train: (LOSS: 0.0637, MAE: 0.0637, RMSE: 0.0994, R2: 0.8451), Valid: (LOSS: 0.0597, MAE: 0.0597, RMSE: 0.0886, R2: 0.8786), PNorm: 164.5547, GNorm: 1.3776
[34/299] timecost: 63.66, lr: 0.000030, Train: (LOSS: 0.0639, MAE: 0.0639, RMSE: 0.0997, R2: 0.8427), Valid: (LOSS: 0.0643, MAE: 0.0643, RMSE: 0.0960, R2: 0.8553), PNorm: 164.3425, GNorm: 3.2761
[35/299] timecost: 64.27, lr: 0.000030, Train: (LOSS: 0.0630, MAE: 0.0630, RMSE: 0.0980, R2: 0.8497), Valid: (LOSS: 0.0773, MAE: 0.0773, RMSE: 0.1172, R2: 0.7848), PNorm: 164.1322, GNorm: 1.6823
[36/299] timecost: 63.00, lr: 0.000030, Train: (LOSS: 0.0621, MAE: 0.0621, RMSE: 0.0954, R2: 0.8545), Valid: (LOSS: 0.0661, MAE: 0.0661, RMSE: 0.0978, R2: 0.8519), PNorm: 163.9234, GNorm: 1.3126
[37/299] timecost: 63.05, lr: 0.000030, Train: (LOSS: 0.0610, MAE: 0.0610, RMSE: 0.0955, R2: 0.8592), Valid: (LOSS: 0.0628, MAE: 0.0628, RMSE: 0.0956, R2: 0.8559), PNorm: 163.7177, GNorm: 1.2262
[38/299] timecost: 63.31, lr: 0.000030, Train: (LOSS: 0.0626, MAE: 0.0626, RMSE: 0.0958, R2: 0.8583), Valid: (LOSS: 0.0607, MAE: 0.0607, RMSE: 0.0917, R2: 0.8682), PNorm: 163.5146, GNorm: 2.0702
[39/299] timecost: 63.27, lr: 0.000030, Train: (LOSS: 0.0576, MAE: 0.0576, RMSE: 0.0903, R2: 0.8746), Valid: (LOSS: 0.0554, MAE: 0.0554, RMSE: 0.0851, R2: 0.8862), PNorm: 163.3127, GNorm: 1.7619
[40/299] timecost: 63.68, lr: 0.000030, Train: (LOSS: 0.0557, MAE: 0.0557, RMSE: 0.0876, R2: 0.8745), Valid: (LOSS: 0.0635, MAE: 0.0635, RMSE: 0.0970, R2: 0.8536), PNorm: 163.1124, GNorm: 1.8815
[41/299] timecost: 63.53, lr: 0.000030, Train: (LOSS: 0.0548, MAE: 0.0548, RMSE: 0.0845, R2: 0.8886), Valid: (LOSS: 0.0562, MAE: 0.0562, RMSE: 0.0851, R2: 0.8863), PNorm: 162.9141, GNorm: 1.7484
[42/299] timecost: 63.88, lr: 0.000030, Train: (LOSS: 0.0543, MAE: 0.0543, RMSE: 0.0844, R2: 0.8861), Valid: (LOSS: 0.0593, MAE: 0.0593, RMSE: 0.0910, R2: 0.8732), PNorm: 162.7168, GNorm: 2.3042
[43/299] timecost: 63.45, lr: 0.000030, Train: (LOSS: 0.0520, MAE: 0.0520, RMSE: 0.0821, R2: 0.8967), Valid: (LOSS: 0.0521, MAE: 0.0521, RMSE: 0.0809, R2: 0.9000), PNorm: 162.5209, GNorm: 1.4644
[44/299] timecost: 64.54, lr: 0.000030, Train: (LOSS: 0.0499, MAE: 0.0499, RMSE: 0.0785, R2: 0.9010), Valid: (LOSS: 0.0563, MAE: 0.0563, RMSE: 0.0857, R2: 0.8825), PNorm: 162.3260, GNorm: 2.4811
[45/299] timecost: 64.71, lr: 0.000030, Train: (LOSS: 0.0508, MAE: 0.0508, RMSE: 0.0795, R2: 0.8951), Valid: (LOSS: 0.0600, MAE: 0.0600, RMSE: 0.0889, R2: 0.8788), PNorm: 162.1340, GNorm: 1.7806
[46/299] timecost: 64.56, lr: 0.000030, Train: (LOSS: 0.0483, MAE: 0.0483, RMSE: 0.0771, R2: 0.9032), Valid: (LOSS: 0.0498, MAE: 0.0498, RMSE: 0.0778, R2: 0.9085), PNorm: 161.9418, GNorm: 1.3417
[47/299] timecost: 64.77, lr: 0.000030, Train: (LOSS: 0.0489, MAE: 0.0489, RMSE: 0.0758, R2: 0.9078), Valid: (LOSS: 0.0566, MAE: 0.0566, RMSE: 0.0856, R2: 0.8894), PNorm: 161.7511, GNorm: 2.3594
[48/299] timecost: 64.62, lr: 0.000030, Train: (LOSS: 0.0469, MAE: 0.0469, RMSE: 0.0745, R2: 0.9126), Valid: (LOSS: 0.0536, MAE: 0.0536, RMSE: 0.0779, R2: 0.9082), PNorm: 161.5623, GNorm: 1.2481
[49/299] timecost: 64.54, lr: 0.000030, Train: (LOSS: 0.0459, MAE: 0.0459, RMSE: 0.0722, R2: 0.9172), Valid: (LOSS: 0.0518, MAE: 0.0518, RMSE: 0.0782, R2: 0.9064), PNorm: 161.3731, GNorm: 0.9767
[50/299] timecost: 64.52, lr: 0.000030, Train: (LOSS: 0.0486, MAE: 0.0486, RMSE: 0.0761, R2: 0.9101), Valid: (LOSS: 0.0570, MAE: 0.0570, RMSE: 0.0828, R2: 0.8966), PNorm: 161.1862, GNorm: 2.4255
[51/299] timecost: 64.67, lr: 0.000030, Train: (LOSS: 0.0466, MAE: 0.0466, RMSE: 0.0718, R2: 0.9122), Valid: (LOSS: 0.0472, MAE: 0.0472, RMSE: 0.0721, R2: 0.9202), PNorm: 160.9998, GNorm: 1.6371
[52/299] timecost: 64.60, lr: 0.000030, Train: (LOSS: 0.0444, MAE: 0.0444, RMSE: 0.0705, R2: 0.9231), Valid: (LOSS: 0.0534, MAE: 0.0534, RMSE: 0.0776, R2: 0.9072), PNorm: 160.8137, GNorm: 1.4487
[53/299] timecost: 64.22, lr: 0.000030, Train: (LOSS: 0.0438, MAE: 0.0438, RMSE: 0.0680, R2: 0.9279), Valid: (LOSS: 0.0472, MAE: 0.0472, RMSE: 0.0705, R2: 0.9237), PNorm: 160.6280, GNorm: 1.7912
[54/299] timecost: 64.77, lr: 0.000030, Train: (LOSS: 0.0446, MAE: 0.0446, RMSE: 0.0692, R2: 0.9233), Valid: (LOSS: 0.0483, MAE: 0.0483, RMSE: 0.0757, R2: 0.9117), PNorm: 160.4433, GNorm: 1.1042
[55/299] timecost: 64.72, lr: 0.000030, Train: (LOSS: 0.0449, MAE: 0.0449, RMSE: 0.0707, R2: 0.9216), Valid: (LOSS: 0.0472, MAE: 0.0472, RMSE: 0.0684, R2: 0.9285), PNorm: 160.2596, GNorm: 1.6949
[56/299] timecost: 64.26, lr: 0.000030, Train: (LOSS: 0.0434, MAE: 0.0434, RMSE: 0.0683, R2: 0.9274), Valid: (LOSS: 0.0485, MAE: 0.0485, RMSE: 0.0727, R2: 0.9198), PNorm: 160.0755, GNorm: 1.4774
[57/299] timecost: 64.20, lr: 0.000030, Train: (LOSS: 0.0437, MAE: 0.0437, RMSE: 0.0680, R2: 0.9270), Valid: (LOSS: 0.0566, MAE: 0.0566, RMSE: 0.0825, R2: 0.8971), PNorm: 159.8923, GNorm: 3.0151
[58/299] timecost: 64.46, lr: 0.000030, Train: (LOSS: 0.0430, MAE: 0.0430, RMSE: 0.0682, R2: 0.9258), Valid: (LOSS: 0.0459, MAE: 0.0459, RMSE: 0.0685, R2: 0.9297), PNorm: 159.7097, GNorm: 1.1465
[59/299] timecost: 64.62, lr: 0.000030, Train: (LOSS: 0.0420, MAE: 0.0420, RMSE: 0.0662, R2: 0.9280), Valid: (LOSS: 0.0523, MAE: 0.0523, RMSE: 0.0773, R2: 0.9079), PNorm: 159.5267, GNorm: 1.3339
[60/299] timecost: 64.28, lr: 0.000030, Train: (LOSS: 0.0405, MAE: 0.0405, RMSE: 0.0648, R2: 0.9314), Valid: (LOSS: 0.0453, MAE: 0.0453, RMSE: 0.0676, R2: 0.9305), PNorm: 159.3433, GNorm: 1.5063
[61/299] timecost: 63.41, lr: 0.000030, Train: (LOSS: 0.0395, MAE: 0.0395, RMSE: 0.0614, R2: 0.9350), Valid: (LOSS: 0.0471, MAE: 0.0471, RMSE: 0.0726, R2: 0.9194), PNorm: 159.1596, GNorm: 1.5648
[62/299] timecost: 63.86, lr: 0.000030, Train: (LOSS: 0.0382, MAE: 0.0382, RMSE: 0.0601, R2: 0.9387), Valid: (LOSS: 0.0422, MAE: 0.0422, RMSE: 0.0644, R2: 0.9374), PNorm: 158.9749, GNorm: 0.9404
[63/299] timecost: 65.26, lr: 0.000030, Train: (LOSS: 0.0375, MAE: 0.0375, RMSE: 0.0587, R2: 0.9420), Valid: (LOSS: 0.0435, MAE: 0.0435, RMSE: 0.0676, R2: 0.9308), PNorm: 158.7901, GNorm: 1.9778
[64/299] timecost: 63.23, lr: 0.000030, Train: (LOSS: 0.0386, MAE: 0.0386, RMSE: 0.0601, R2: 0.9416), Valid: (LOSS: 0.0458, MAE: 0.0458, RMSE: 0.0694, R2: 0.9244), PNorm: 158.6058, GNorm: 2.2204
[65/299] timecost: 64.03, lr: 0.000030, Train: (LOSS: 0.0391, MAE: 0.0391, RMSE: 0.0616, R2: 0.9357), Valid: (LOSS: 0.0459, MAE: 0.0459, RMSE: 0.0683, R2: 0.9283), PNorm: 158.4214, GNorm: 1.5145
[66/299] timecost: 63.92, lr: 0.000030, Train: (LOSS: 0.0382, MAE: 0.0382, RMSE: 0.0596, R2: 0.9413), Valid: (LOSS: 0.0464, MAE: 0.0464, RMSE: 0.0686, R2: 0.9295), PNorm: 158.2359, GNorm: 0.9879
[67/299] timecost: 63.61, lr: 0.000030, Train: (LOSS: 0.0371, MAE: 0.0371, RMSE: 0.0585, R2: 0.9445), Valid: (LOSS: 0.0445, MAE: 0.0445, RMSE: 0.0682, R2: 0.9288), PNorm: 158.0496, GNorm: 1.4749
[68/299] timecost: 63.32, lr: 0.000030, Train: (LOSS: 0.0366, MAE: 0.0366, RMSE: 0.0580, R2: 0.9450), Valid: (LOSS: 0.0468, MAE: 0.0468, RMSE: 0.0691, R2: 0.9274), PNorm: 157.8629, GNorm: 2.0395
[69/299] timecost: 64.11, lr: 0.000030, Train: (LOSS: 0.0367, MAE: 0.0367, RMSE: 0.0573, R2: 0.9462), Valid: (LOSS: 0.0435, MAE: 0.0435, RMSE: 0.0654, R2: 0.9347), PNorm: 157.6762, GNorm: 0.8201
[70/299] timecost: 63.78, lr: 0.000030, Train: (LOSS: 0.0365, MAE: 0.0365, RMSE: 0.0577, R2: 0.9459), Valid: (LOSS: 0.0445, MAE: 0.0445, RMSE: 0.0656, R2: 0.9338), PNorm: 157.4889, GNorm: 0.9878
[71/299] timecost: 64.41, lr: 0.000030, Train: (LOSS: 0.0352, MAE: 0.0352, RMSE: 0.0560, R2: 0.9470), Valid: (LOSS: 0.0465, MAE: 0.0465, RMSE: 0.0702, R2: 0.9211), PNorm: 157.2999, GNorm: 1.8731
[72/299] timecost: 64.11, lr: 0.000030, Train: (LOSS: 0.0363, MAE: 0.0363, RMSE: 0.0566, R2: 0.9479), Valid: (LOSS: 0.0429, MAE: 0.0429, RMSE: 0.0644, R2: 0.9373), PNorm: 157.1116, GNorm: 1.1539
[73/299] timecost: 64.18, lr: 0.000030, Train: (LOSS: 0.0357, MAE: 0.0357, RMSE: 0.0561, R2: 0.9474), Valid: (LOSS: 0.0434, MAE: 0.0434, RMSE: 0.0680, R2: 0.9302), PNorm: 156.9219, GNorm: 1.0135
[74/299] timecost: 63.79, lr: 0.000030, Train: (LOSS: 0.0341, MAE: 0.0341, RMSE: 0.0538, R2: 0.9528), Valid: (LOSS: 0.0423, MAE: 0.0423, RMSE: 0.0631, R2: 0.9393), PNorm: 156.7300, GNorm: 1.3528
[75/299] timecost: 63.14, lr: 0.000030, Train: (LOSS: 0.0346, MAE: 0.0346, RMSE: 0.0543, R2: 0.9488), Valid: (LOSS: 0.0421, MAE: 0.0421, RMSE: 0.0636, R2: 0.9380), PNorm: 156.5380, GNorm: 1.1579
[76/299] timecost: 63.21, lr: 0.000030, Train: (LOSS: 0.0409, MAE: 0.0409, RMSE: 0.0651, R2: 0.9309), Valid: (LOSS: 0.0409, MAE: 0.0409, RMSE: 0.0618, R2: 0.9409), PNorm: 156.3478, GNorm: 1.5539
[77/299] timecost: 64.46, lr: 0.000030, Train: (LOSS: 0.0353, MAE: 0.0353, RMSE: 0.0545, R2: 0.9520), Valid: (LOSS: 0.0415, MAE: 0.0415, RMSE: 0.0610, R2: 0.9412), PNorm: 156.1557, GNorm: 1.3642
[78/299] timecost: 64.26, lr: 0.000030, Train: (LOSS: 0.0321, MAE: 0.0321, RMSE: 0.0504, R2: 0.9558), Valid: (LOSS: 0.0404, MAE: 0.0404, RMSE: 0.0627, R2: 0.9400), PNorm: 155.9614, GNorm: 1.4485
[79/299] timecost: 64.13, lr: 0.000030, Train: (LOSS: 0.0332, MAE: 0.0332, RMSE: 0.0531, R2: 0.9561), Valid: (LOSS: 0.0525, MAE: 0.0525, RMSE: 0.0755, R2: 0.9105), PNorm: 155.7663, GNorm: 1.2665
[80/299] timecost: 63.86, lr: 0.000030, Train: (LOSS: 0.0324, MAE: 0.0324, RMSE: 0.0518, R2: 0.9550), Valid: (LOSS: 0.0413, MAE: 0.0413, RMSE: 0.0617, R2: 0.9421), PNorm: 155.5707, GNorm: 1.5510
[81/299] timecost: 64.00, lr: 0.000030, Train: (LOSS: 0.0324, MAE: 0.0324, RMSE: 0.0525, R2: 0.9542), Valid: (LOSS: 0.0402, MAE: 0.0402, RMSE: 0.0621, R2: 0.9410), PNorm: 155.3728, GNorm: 1.1633
[82/299] timecost: 64.16, lr: 0.000030, Train: (LOSS: 0.0318, MAE: 0.0318, RMSE: 0.0509, R2: 0.9555), Valid: (LOSS: 0.0411, MAE: 0.0411, RMSE: 0.0646, R2: 0.9370), PNorm: 155.1746, GNorm: 0.9625
[83/299] timecost: 64.09, lr: 0.000030, Train: (LOSS: 0.0314, MAE: 0.0314, RMSE: 0.0497, R2: 0.9548), Valid: (LOSS: 0.0458, MAE: 0.0458, RMSE: 0.0673, R2: 0.9305), PNorm: 154.9753, GNorm: 1.5790
[84/299] timecost: 63.72, lr: 0.000030, Train: (LOSS: 0.0324, MAE: 0.0324, RMSE: 0.0507, R2: 0.9562), Valid: (LOSS: 0.0463, MAE: 0.0463, RMSE: 0.0683, R2: 0.9286), PNorm: 154.7753, GNorm: 1.3671
[85/299] timecost: 64.26, lr: 0.000030, Train: (LOSS: 0.0314, MAE: 0.0314, RMSE: 0.0505, R2: 0.9561), Valid: (LOSS: 0.0419, MAE: 0.0419, RMSE: 0.0626, R2: 0.9409), PNorm: 154.5735, GNorm: 1.2907
[86/299] timecost: 64.08, lr: 0.000030, Train: (LOSS: 0.0315, MAE: 0.0315, RMSE: 0.0491, R2: 0.9564), Valid: (LOSS: 0.0402, MAE: 0.0402, RMSE: 0.0624, R2: 0.9401), PNorm: 154.3715, GNorm: 1.1423
[87/299] timecost: 63.81, lr: 0.000030, Train: (LOSS: 0.0294, MAE: 0.0294, RMSE: 0.0480, R2: 0.9582), Valid: (LOSS: 0.0435, MAE: 0.0435, RMSE: 0.0656, R2: 0.9349), PNorm: 154.1677, GNorm: 1.0130
[88/299] timecost: 64.22, lr: 0.000030, Train: (LOSS: 0.0309, MAE: 0.0309, RMSE: 0.0483, R2: 0.9581), Valid: (LOSS: 0.0385, MAE: 0.0385, RMSE: 0.0582, R2: 0.9485), PNorm: 153.9639, GNorm: 1.1341
[89/299] timecost: 63.27, lr: 0.000030, Train: (LOSS: 0.0302, MAE: 0.0302, RMSE: 0.0473, R2: 0.9620), Valid: (LOSS: 0.0408, MAE: 0.0408, RMSE: 0.0627, R2: 0.9385), PNorm: 153.7593, GNorm: 1.1197
[90/299] timecost: 63.07, lr: 0.000030, Train: (LOSS: 0.0304, MAE: 0.0304, RMSE: 0.0481, R2: 0.9601), Valid: (LOSS: 0.0392, MAE: 0.0392, RMSE: 0.0595, R2: 0.9462), PNorm: 153.5532, GNorm: 1.1028
[91/299] timecost: 63.25, lr: 0.000030, Train: (LOSS: 0.0291, MAE: 0.0291, RMSE: 0.0469, R2: 0.9634), Valid: (LOSS: 0.0416, MAE: 0.0416, RMSE: 0.0626, R2: 0.9400), PNorm: 153.3459, GNorm: 0.9172
[92/299] timecost: 63.19, lr: 0.000030, Train: (LOSS: 0.0294, MAE: 0.0294, RMSE: 0.0470, R2: 0.9621), Valid: (LOSS: 0.0401, MAE: 0.0401, RMSE: 0.0616, R2: 0.9420), PNorm: 153.1383, GNorm: 1.0551
[93/299] timecost: 62.96, lr: 0.000030, Train: (LOSS: 0.0296, MAE: 0.0296, RMSE: 0.0468, R2: 0.9615), Valid: (LOSS: 0.0375, MAE: 0.0375, RMSE: 0.0565, R2: 0.9510), PNorm: 152.9293, GNorm: 1.1120
[94/299] timecost: 63.32, lr: 0.000030, Train: (LOSS: 0.0303, MAE: 0.0303, RMSE: 0.0476, R2: 0.9606), Valid: (LOSS: 0.0394, MAE: 0.0394, RMSE: 0.0594, R2: 0.9462), PNorm: 152.7205, GNorm: 1.6743
[95/299] timecost: 62.92, lr: 0.000030, Train: (LOSS: 0.0289, MAE: 0.0289, RMSE: 0.0460, R2: 0.9640), Valid: (LOSS: 0.0417, MAE: 0.0417, RMSE: 0.0633, R2: 0.9383), PNorm: 152.5109, GNorm: 0.9407
[96/299] timecost: 62.96, lr: 0.000030, Train: (LOSS: 0.0288, MAE: 0.0288, RMSE: 0.0465, R2: 0.9608), Valid: (LOSS: 0.0420, MAE: 0.0420, RMSE: 0.0639, R2: 0.9371), PNorm: 152.2993, GNorm: 1.1891
[97/299] timecost: 63.60, lr: 0.000030, Train: (LOSS: 0.0279, MAE: 0.0279, RMSE: 0.0450, R2: 0.9651), Valid: (LOSS: 0.0380, MAE: 0.0380, RMSE: 0.0592, R2: 0.9467), PNorm: 152.0879, GNorm: 1.2411
[98/299] timecost: 64.03, lr: 0.000030, Train: (LOSS: 0.0281, MAE: 0.0281, RMSE: 0.0456, R2: 0.9634), Valid: (LOSS: 0.0420, MAE: 0.0420, RMSE: 0.0646, R2: 0.9365), PNorm: 151.8746, GNorm: 1.1961
[99/299] timecost: 63.70, lr: 0.000030, Train: (LOSS: 0.0279, MAE: 0.0279, RMSE: 0.0446, R2: 0.9654), Valid: (LOSS: 0.0401, MAE: 0.0401, RMSE: 0.0615, R2: 0.9414), PNorm: 151.6617, GNorm: 1.4550
[100/299] timecost: 63.88, lr: 0.000030, Train: (LOSS: 0.0293, MAE: 0.0293, RMSE: 0.0473, R2: 0.9634), Valid: (LOSS: 0.0396, MAE: 0.0396, RMSE: 0.0597, R2: 0.9449), PNorm: 151.4495, GNorm: 1.0066
[101/299] timecost: 63.99, lr: 0.000030, Train: (LOSS: 0.0277, MAE: 0.0277, RMSE: 0.0445, R2: 0.9662), Valid: (LOSS: 0.0413, MAE: 0.0413, RMSE: 0.0623, R2: 0.9399), PNorm: 151.2347, GNorm: 1.0840
[102/299] timecost: 64.36, lr: 0.000030, Train: (LOSS: 0.0278, MAE: 0.0278, RMSE: 0.0445, R2: 0.9648), Valid: (LOSS: 0.0410, MAE: 0.0410, RMSE: 0.0601, R2: 0.9458), PNorm: 151.0199, GNorm: 1.0282
[103/299] timecost: 63.79, lr: 0.000030, Train: (LOSS: 0.0271, MAE: 0.0271, RMSE: 0.0444, R2: 0.9661), Valid: (LOSS: 0.0408, MAE: 0.0408, RMSE: 0.0615, R2: 0.9417), PNorm: 150.8044, GNorm: 0.9631
[104/299] timecost: 62.95, lr: 0.000030, Train: (LOSS: 0.0269, MAE: 0.0269, RMSE: 0.0434, R2: 0.9691), Valid: (LOSS: 0.0392, MAE: 0.0392, RMSE: 0.0582, R2: 0.9483), PNorm: 150.5885, GNorm: 1.3174
[105/299] timecost: 63.21, lr: 0.000030, Train: (LOSS: 0.0256, MAE: 0.0256, RMSE: 0.0423, R2: 0.9684), Valid: (LOSS: 0.0400, MAE: 0.0400, RMSE: 0.0606, R2: 0.9437), PNorm: 150.3726, GNorm: 0.9814
[106/299] timecost: 62.81, lr: 0.000030, Train: (LOSS: 0.0278, MAE: 0.0278, RMSE: 0.0452, R2: 0.9647), Valid: (LOSS: 0.0413, MAE: 0.0413, RMSE: 0.0629, R2: 0.9393), PNorm: 150.1565, GNorm: 1.1170
[107/299] timecost: 63.26, lr: 0.000030, Train: (LOSS: 0.0282, MAE: 0.0282, RMSE: 0.0464, R2: 0.9624), Valid: (LOSS: 0.0393, MAE: 0.0393, RMSE: 0.0605, R2: 0.9438), PNorm: 149.9409, GNorm: 0.8631
[108/299] timecost: 63.00, lr: 0.000030, Train: (LOSS: 0.0264, MAE: 0.0264, RMSE: 0.0429, R2: 0.9682), Valid: (LOSS: 0.0383, MAE: 0.0383, RMSE: 0.0578, R2: 0.9491), PNorm: 149.7249, GNorm: 1.0582
[109/299] timecost: 62.77, lr: 0.000030, Train: (LOSS: 0.0259, MAE: 0.0259, RMSE: 0.0420, R2: 0.9696), Valid: (LOSS: 0.0432, MAE: 0.0432, RMSE: 0.0650, R2: 0.9353), PNorm: 149.5089, GNorm: 0.8185
[110/299] timecost: 63.10, lr: 0.000030, Train: (LOSS: 0.0264, MAE: 0.0264, RMSE: 0.0416, R2: 0.9697), Valid: (LOSS: 0.0403, MAE: 0.0403, RMSE: 0.0610, R2: 0.9428), PNorm: 149.2933, GNorm: 1.0144
[111/299] timecost: 64.12, lr: 0.000030, Train: (LOSS: 0.0271, MAE: 0.0271, RMSE: 0.0428, R2: 0.9690), Valid: (LOSS: 0.0383, MAE: 0.0383, RMSE: 0.0582, R2: 0.9475), PNorm: 149.0783, GNorm: 1.2380
[112/299] timecost: 64.16, lr: 0.000030, Train: (LOSS: 0.0251, MAE: 0.0251, RMSE: 0.0406, R2: 0.9723), Valid: (LOSS: 0.0404, MAE: 0.0404, RMSE: 0.0629, R2: 0.9363), PNorm: 148.8622, GNorm: 0.8077
[113/299] timecost: 63.97, lr: 0.000030, Train: (LOSS: 0.0247, MAE: 0.0247, RMSE: 0.0400, R2: 0.9719), Valid: (LOSS: 0.0403, MAE: 0.0403, RMSE: 0.0602, R2: 0.9441), PNorm: 148.6458, GNorm: 1.0709
[114/299] timecost: 63.41, lr: 0.000030, Train: (LOSS: 0.0236, MAE: 0.0236, RMSE: 0.0388, R2: 0.9742), Valid: (LOSS: 0.0369, MAE: 0.0369, RMSE: 0.0564, R2: 0.9521), PNorm: 148.4300, GNorm: 0.8575
[115/299] timecost: 62.83, lr: 0.000030, Train: (LOSS: 0.0239, MAE: 0.0239, RMSE: 0.0390, R2: 0.9720), Valid: (LOSS: 0.0419, MAE: 0.0419, RMSE: 0.0607, R2: 0.9442), PNorm: 148.2143, GNorm: 1.0454
[116/299] timecost: 63.19, lr: 0.000030, Train: (LOSS: 0.0249, MAE: 0.0249, RMSE: 0.0400, R2: 0.9732), Valid: (LOSS: 0.0372, MAE: 0.0372, RMSE: 0.0576, R2: 0.9497), PNorm: 147.9995, GNorm: 0.9715
[117/299] timecost: 62.92, lr: 0.000030, Train: (LOSS: 0.0246, MAE: 0.0246, RMSE: 0.0403, R2: 0.9729), Valid: (LOSS: 0.0403, MAE: 0.0403, RMSE: 0.0606, R2: 0.9437), PNorm: 147.7850, GNorm: 0.9514
[118/299] timecost: 63.46, lr: 0.000030, Train: (LOSS: 0.0247, MAE: 0.0247, RMSE: 0.0410, R2: 0.9705), Valid: (LOSS: 0.0430, MAE: 0.0430, RMSE: 0.0635, R2: 0.9381), PNorm: 147.5711, GNorm: 1.5516
[119/299] timecost: 63.83, lr: 0.000030, Train: (LOSS: 0.0249, MAE: 0.0249, RMSE: 0.0404, R2: 0.9720), Valid: (LOSS: 0.0381, MAE: 0.0381, RMSE: 0.0582, R2: 0.9486), PNorm: 147.3577, GNorm: 0.9706
[120/299] timecost: 63.46, lr: 0.000030, Train: (LOSS: 0.0237, MAE: 0.0237, RMSE: 0.0385, R2: 0.9736), Valid: (LOSS: 0.0385, MAE: 0.0385, RMSE: 0.0588, R2: 0.9472), PNorm: 147.1455, GNorm: 1.1083
[121/299] timecost: 63.04, lr: 0.000030, Train: (LOSS: 0.0249, MAE: 0.0249, RMSE: 0.0405, R2: 0.9724), Valid: (LOSS: 0.0416, MAE: 0.0416, RMSE: 0.0639, R2: 0.9358), PNorm: 146.9327, GNorm: 1.1138
[122/299] timecost: 62.96, lr: 0.000030, Train: (LOSS: 0.0261, MAE: 0.0261, RMSE: 0.0432, R2: 0.9661), Valid: (LOSS: 0.0391, MAE: 0.0391, RMSE: 0.0603, R2: 0.9441), PNorm: 146.7245, GNorm: 0.9722
[123/299] timecost: 62.83, lr: 0.000030, Train: (LOSS: 0.0257, MAE: 0.0257, RMSE: 0.0408, R2: 0.9713), Valid: (LOSS: 0.0404, MAE: 0.0404, RMSE: 0.0645, R2: 0.9335), PNorm: 146.5153, GNorm: 0.9483
[124/299] timecost: 62.82, lr: 0.000030, Train: (LOSS: 0.0244, MAE: 0.0244, RMSE: 0.0395, R2: 0.9733), Valid: (LOSS: 0.0389, MAE: 0.0389, RMSE: 0.0591, R2: 0.9474), PNorm: 146.3082, GNorm: 1.1988
[125/299] timecost: 62.74, lr: 0.000030, Train: (LOSS: 0.0240, MAE: 0.0240, RMSE: 0.0388, R2: 0.9747), Valid: (LOSS: 0.0399, MAE: 0.0399, RMSE: 0.0622, R2: 0.9415), PNorm: 146.1014, GNorm: 1.0152
[126/299] timecost: 63.44, lr: 0.000030, Train: (LOSS: 0.0237, MAE: 0.0237, RMSE: 0.0391, R2: 0.9731), Valid: (LOSS: 0.0389, MAE: 0.0389, RMSE: 0.0595, R2: 0.9451), PNorm: 145.8964, GNorm: 1.1432
[127/299] timecost: 63.96, lr: 0.000030, Train: (LOSS: 0.0234, MAE: 0.0234, RMSE: 0.0374, R2: 0.9739), Valid: (LOSS: 0.0395, MAE: 0.0395, RMSE: 0.0605, R2: 0.9432), PNorm: 145.6916, GNorm: 0.8857
[128/299] timecost: 63.95, lr: 0.000030, Train: (LOSS: 0.0242, MAE: 0.0242, RMSE: 0.0386, R2: 0.9742), Valid: (LOSS: 0.0391, MAE: 0.0391, RMSE: 0.0595, R2: 0.9457), PNorm: 145.4885, GNorm: 0.7653
[129/299] timecost: 63.09, lr: 0.000030, Train: (LOSS: 0.0227, MAE: 0.0227, RMSE: 0.0371, R2: 0.9731), Valid: (LOSS: 0.0402, MAE: 0.0402, RMSE: 0.0624, R2: 0.9399), PNorm: 145.2856, GNorm: 0.9811
[130/299] timecost: 63.22, lr: 0.000030, Train: (LOSS: 0.0229, MAE: 0.0229, RMSE: 0.0379, R2: 0.9746), Valid: (LOSS: 0.0399, MAE: 0.0399, RMSE: 0.0615, R2: 0.9405), PNorm: 145.0848, GNorm: 1.0543
[131/299] timecost: 63.29, lr: 0.000030, Train: (LOSS: 0.0230, MAE: 0.0230, RMSE: 0.0366, R2: 0.9762), Valid: (LOSS: 0.0427, MAE: 0.0427, RMSE: 0.0641, R2: 0.9357), PNorm: 144.8842, GNorm: 1.5997
[132/299] timecost: 63.48, lr: 0.000030, Train: (LOSS: 0.0224, MAE: 0.0224, RMSE: 0.0362, R2: 0.9760), Valid: (LOSS: 0.0367, MAE: 0.0367, RMSE: 0.0562, R2: 0.9514), PNorm: 144.6871, GNorm: 0.9899
[133/299] timecost: 63.37, lr: 0.000030, Train: (LOSS: 0.0220, MAE: 0.0220, RMSE: 0.0358, R2: 0.9766), Valid: (LOSS: 0.0398, MAE: 0.0398, RMSE: 0.0606, R2: 0.9441), PNorm: 144.4902, GNorm: 0.9831
[134/299] timecost: 63.44, lr: 0.000030, Train: (LOSS: 0.0217, MAE: 0.0217, RMSE: 0.0356, R2: 0.9765), Valid: (LOSS: 0.0347, MAE: 0.0347, RMSE: 0.0537, R2: 0.9561), PNorm: 144.2947, GNorm: 0.8378
[135/299] timecost: 63.76, lr: 0.000030, Train: (LOSS: 0.0225, MAE: 0.0225, RMSE: 0.0367, R2: 0.9768), Valid: (LOSS: 0.0380, MAE: 0.0380, RMSE: 0.0573, R2: 0.9503), PNorm: 144.1018, GNorm: 1.4808
[136/299] timecost: 63.69, lr: 0.000030, Train: (LOSS: 0.0215, MAE: 0.0215, RMSE: 0.0344, R2: 0.9780), Valid: (LOSS: 0.0386, MAE: 0.0386, RMSE: 0.0589, R2: 0.9467), PNorm: 143.9103, GNorm: 0.9331
[137/299] timecost: 63.12, lr: 0.000030, Train: (LOSS: 0.0208, MAE: 0.0208, RMSE: 0.0334, R2: 0.9805), Valid: (LOSS: 0.0397, MAE: 0.0397, RMSE: 0.0602, R2: 0.9450), PNorm: 143.7195, GNorm: 0.9449
[138/299] timecost: 63.33, lr: 0.000030, Train: (LOSS: 0.0207, MAE: 0.0207, RMSE: 0.0332, R2: 0.9800), Valid: (LOSS: 0.0358, MAE: 0.0358, RMSE: 0.0537, R2: 0.9568), PNorm: 143.5314, GNorm: 0.8085
[139/299] timecost: 63.32, lr: 0.000030, Train: (LOSS: 0.0204, MAE: 0.0204, RMSE: 0.0335, R2: 0.9798), Valid: (LOSS: 0.0363, MAE: 0.0363, RMSE: 0.0565, R2: 0.9522), PNorm: 143.3446, GNorm: 1.3480
[140/299] timecost: 63.36, lr: 0.000030, Train: (LOSS: 0.0210, MAE: 0.0210, RMSE: 0.0337, R2: 0.9791), Valid: (LOSS: 0.0372, MAE: 0.0372, RMSE: 0.0574, R2: 0.9502), PNorm: 143.1587, GNorm: 0.7610
[141/299] timecost: 63.18, lr: 0.000030, Train: (LOSS: 0.0230, MAE: 0.0230, RMSE: 0.0366, R2: 0.9765), Valid: (LOSS: 0.0396, MAE: 0.0396, RMSE: 0.0595, R2: 0.9468), PNorm: 142.9763, GNorm: 0.8343
[142/299] timecost: 62.98, lr: 0.000030, Train: (LOSS: 0.0200, MAE: 0.0200, RMSE: 0.0325, R2: 0.9814), Valid: (LOSS: 0.0402, MAE: 0.0402, RMSE: 0.0601, R2: 0.9446), PNorm: 142.7948, GNorm: 0.9644
[143/299] timecost: 63.47, lr: 0.000030, Train: (LOSS: 0.0209, MAE: 0.0209, RMSE: 0.0343, R2: 0.9792), Valid: (LOSS: 0.0359, MAE: 0.0359, RMSE: 0.0538, R2: 0.9560), PNorm: 142.6172, GNorm: 1.1709
[144/299] timecost: 63.68, lr: 0.000030, Train: (LOSS: 0.0203, MAE: 0.0203, RMSE: 0.0328, R2: 0.9821), Valid: (LOSS: 0.0375, MAE: 0.0375, RMSE: 0.0590, R2: 0.9461), PNorm: 142.4399, GNorm: 0.8933
[145/299] timecost: 63.69, lr: 0.000030, Train: (LOSS: 0.0206, MAE: 0.0206, RMSE: 0.0334, R2: 0.9798), Valid: (LOSS: 0.0393, MAE: 0.0393, RMSE: 0.0576, R2: 0.9498), PNorm: 142.2649, GNorm: 0.9275
[146/299] timecost: 62.71, lr: 0.000030, Train: (LOSS: 0.0189, MAE: 0.0189, RMSE: 0.0313, R2: 0.9827), Valid: (LOSS: 0.0342, MAE: 0.0342, RMSE: 0.0528, R2: 0.9574), PNorm: 142.0918, GNorm: 0.7364
[147/299] timecost: 62.60, lr: 0.000030, Train: (LOSS: 0.0200, MAE: 0.0200, RMSE: 0.0326, R2: 0.9795), Valid: (LOSS: 0.0357, MAE: 0.0357, RMSE: 0.0552, R2: 0.9530), PNorm: 141.9207, GNorm: 0.8774
[148/299] timecost: 62.71, lr: 0.000030, Train: (LOSS: 0.0198, MAE: 0.0198, RMSE: 0.0322, R2: 0.9817), Valid: (LOSS: 0.0360, MAE: 0.0360, RMSE: 0.0549, R2: 0.9545), PNorm: 141.7523, GNorm: 1.0371
[149/299] timecost: 63.18, lr: 0.000030, Train: (LOSS: 0.0202, MAE: 0.0202, RMSE: 0.0324, R2: 0.9807), Valid: (LOSS: 0.0367, MAE: 0.0367, RMSE: 0.0557, R2: 0.9528), PNorm: 141.5864, GNorm: 0.9124
[150/299] timecost: 63.08, lr: 0.000030, Train: (LOSS: 0.0199, MAE: 0.0199, RMSE: 0.0322, R2: 0.9809), Valid: (LOSS: 0.0395, MAE: 0.0395, RMSE: 0.0581, R2: 0.9487), PNorm: 141.4227, GNorm: 1.0157
[151/299] timecost: 62.99, lr: 0.000030, Train: (LOSS: 0.0191, MAE: 0.0191, RMSE: 0.0309, R2: 0.9821), Valid: (LOSS: 0.0368, MAE: 0.0368, RMSE: 0.0539, R2: 0.9558), PNorm: 141.2602, GNorm: 0.9308
[152/299] timecost: 62.99, lr: 0.000030, Train: (LOSS: 0.0184, MAE: 0.0184, RMSE: 0.0300, R2: 0.9826), Valid: (LOSS: 0.0353, MAE: 0.0353, RMSE: 0.0540, R2: 0.9557), PNorm: 141.0999, GNorm: 0.8977
[153/299] timecost: 62.73, lr: 0.000030, Train: (LOSS: 0.0185, MAE: 0.0185, RMSE: 0.0305, R2: 0.9828), Valid: (LOSS: 0.0360, MAE: 0.0360, RMSE: 0.0552, R2: 0.9541), PNorm: 140.9415, GNorm: 0.8770
[154/299] timecost: 62.71, lr: 0.000030, Train: (LOSS: 0.0181, MAE: 0.0181, RMSE: 0.0293, R2: 0.9834), Valid: (LOSS: 0.0360, MAE: 0.0360, RMSE: 0.0551, R2: 0.9528), PNorm: 140.7850, GNorm: 0.8867
[155/299] timecost: 63.41, lr: 0.000030, Train: (LOSS: 0.0182, MAE: 0.0182, RMSE: 0.0298, R2: 0.9826), Valid: (LOSS: 0.0375, MAE: 0.0375, RMSE: 0.0570, R2: 0.9500), PNorm: 140.6307, GNorm: 0.8831
[156/299] timecost: 63.69, lr: 0.000030, Train: (LOSS: 0.0186, MAE: 0.0186, RMSE: 0.0302, R2: 0.9843), Valid: (LOSS: 0.0370, MAE: 0.0370, RMSE: 0.0555, R2: 0.9530), PNorm: 140.4784, GNorm: 0.7637
[157/299] timecost: 64.25, lr: 0.000030, Train: (LOSS: 0.0174, MAE: 0.0174, RMSE: 0.0286, R2: 0.9839), Valid: (LOSS: 0.0356, MAE: 0.0356, RMSE: 0.0536, R2: 0.9561), PNorm: 140.3289, GNorm: 1.0072
[158/299] timecost: 63.96, lr: 0.000030, Train: (LOSS: 0.0189, MAE: 0.0189, RMSE: 0.0302, R2: 0.9841), Valid: (LOSS: 0.0371, MAE: 0.0371, RMSE: 0.0588, R2: 0.9463), PNorm: 140.1812, GNorm: 1.4705
[159/299] timecost: 63.82, lr: 0.000030, Train: (LOSS: 0.0179, MAE: 0.0179, RMSE: 0.0290, R2: 0.9852), Valid: (LOSS: 0.0342, MAE: 0.0342, RMSE: 0.0522, R2: 0.9580), PNorm: 140.0351, GNorm: 0.8340
[160/299] timecost: 62.76, lr: 0.000030, Train: (LOSS: 0.0172, MAE: 0.0172, RMSE: 0.0283, R2: 0.9851), Valid: (LOSS: 0.0365, MAE: 0.0365, RMSE: 0.0554, R2: 0.9527), PNorm: 139.8911, GNorm: 0.7599
[161/299] timecost: 62.97, lr: 0.000030, Train: (LOSS: 0.0184, MAE: 0.0184, RMSE: 0.0297, R2: 0.9842), Valid: (LOSS: 0.0359, MAE: 0.0359, RMSE: 0.0527, R2: 0.9582), PNorm: 139.7493, GNorm: 0.8421
[162/299] timecost: 63.35, lr: 0.000030, Train: (LOSS: 0.0179, MAE: 0.0179, RMSE: 0.0291, R2: 0.9848), Valid: (LOSS: 0.0372, MAE: 0.0372, RMSE: 0.0558, R2: 0.9522), PNorm: 139.6105, GNorm: 0.9073
[163/299] timecost: 63.02, lr: 0.000030, Train: (LOSS: 0.0176, MAE: 0.0176, RMSE: 0.0288, R2: 0.9854), Valid: (LOSS: 0.0364, MAE: 0.0364, RMSE: 0.0549, R2: 0.9544), PNorm: 139.4724, GNorm: 0.8772
[164/299] timecost: 63.36, lr: 0.000030, Train: (LOSS: 0.0182, MAE: 0.0182, RMSE: 0.0289, R2: 0.9842), Valid: (LOSS: 0.0355, MAE: 0.0355, RMSE: 0.0542, R2: 0.9552), PNorm: 139.3374, GNorm: 0.8077
[165/299] timecost: 63.55, lr: 0.000030, Train: (LOSS: 0.0175, MAE: 0.0175, RMSE: 0.0278, R2: 0.9862), Valid: (LOSS: 0.0367, MAE: 0.0367, RMSE: 0.0554, R2: 0.9531), PNorm: 139.2035, GNorm: 0.8599
[166/299] timecost: 63.27, lr: 0.000030, Train: (LOSS: 0.0177, MAE: 0.0177, RMSE: 0.0284, R2: 0.9850), Valid: (LOSS: 0.0359, MAE: 0.0359, RMSE: 0.0547, R2: 0.9534), PNorm: 139.0718, GNorm: 1.4660
Epoch 00168: reducing learning rate of group 0 to 2.7000e-05.
[167/299] timecost: 63.22, lr: 0.000027, Train: (LOSS: 0.0172, MAE: 0.0172, RMSE: 0.0277, R2: 0.9862), Valid: (LOSS: 0.0373, MAE: 0.0373, RMSE: 0.0561, R2: 0.9513), PNorm: 138.9427, GNorm: 0.8578
[168/299] timecost: 63.02, lr: 0.000027, Train: (LOSS: 0.0167, MAE: 0.0167, RMSE: 0.0271, R2: 0.9861), Valid: (LOSS: 0.0379, MAE: 0.0379, RMSE: 0.0570, R2: 0.9501), PNorm: 138.8270, GNorm: 0.6246
[169/299] timecost: 63.12, lr: 0.000027, Train: (LOSS: 0.0160, MAE: 0.0160, RMSE: 0.0258, R2: 0.9876), Valid: (LOSS: 0.0352, MAE: 0.0352, RMSE: 0.0532, R2: 0.9569), PNorm: 138.7132, GNorm: 0.9595
[170/299] timecost: 63.08, lr: 0.000027, Train: (LOSS: 0.0158, MAE: 0.0158, RMSE: 0.0258, R2: 0.9868), Valid: (LOSS: 0.0364, MAE: 0.0364, RMSE: 0.0549, R2: 0.9530), PNorm: 138.5994, GNorm: 0.7839
[171/299] timecost: 63.05, lr: 0.000027, Train: (LOSS: 0.0156, MAE: 0.0156, RMSE: 0.0256, R2: 0.9875), Valid: (LOSS: 0.0354, MAE: 0.0354, RMSE: 0.0535, R2: 0.9554), PNorm: 138.4871, GNorm: 0.6248
[172/299] timecost: 63.17, lr: 0.000027, Train: (LOSS: 0.0154, MAE: 0.0154, RMSE: 0.0250, R2: 0.9873), Valid: (LOSS: 0.0369, MAE: 0.0369, RMSE: 0.0550, R2: 0.9543), PNorm: 138.3760, GNorm: 0.8606
[173/299] timecost: 64.23, lr: 0.000027, Train: (LOSS: 0.0161, MAE: 0.0161, RMSE: 0.0258, R2: 0.9875), Valid: (LOSS: 0.0382, MAE: 0.0382, RMSE: 0.0555, R2: 0.9528), PNorm: 138.2657, GNorm: 1.1642
[174/299] timecost: 64.05, lr: 0.000027, Train: (LOSS: 0.0162, MAE: 0.0162, RMSE: 0.0258, R2: 0.9876), Valid: (LOSS: 0.0336, MAE: 0.0336, RMSE: 0.0512, R2: 0.9603), PNorm: 138.1569, GNorm: 0.9230
[175/299] timecost: 63.88, lr: 0.000027, Train: (LOSS: 0.0153, MAE: 0.0153, RMSE: 0.0249, R2: 0.9882), Valid: (LOSS: 0.0362, MAE: 0.0362, RMSE: 0.0542, R2: 0.9552), PNorm: 138.0494, GNorm: 0.8206
[176/299] timecost: 63.91, lr: 0.000027, Train: (LOSS: 0.0156, MAE: 0.0156, RMSE: 0.0257, R2: 0.9867), Valid: (LOSS: 0.0355, MAE: 0.0355, RMSE: 0.0549, R2: 0.9543), PNorm: 137.9435, GNorm: 0.8824
[177/299] timecost: 63.80, lr: 0.000027, Train: (LOSS: 0.0157, MAE: 0.0157, RMSE: 0.0253, R2: 0.9863), Valid: (LOSS: 0.0357, MAE: 0.0357, RMSE: 0.0532, R2: 0.9576), PNorm: 137.8385, GNorm: 1.0753
[178/299] timecost: 63.50, lr: 0.000027, Train: (LOSS: 0.0154, MAE: 0.0154, RMSE: 0.0253, R2: 0.9880), Valid: (LOSS: 0.0341, MAE: 0.0341, RMSE: 0.0524, R2: 0.9585), PNorm: 137.7350, GNorm: 0.8815
[179/299] timecost: 63.64, lr: 0.000027, Train: (LOSS: 0.0157, MAE: 0.0157, RMSE: 0.0256, R2: 0.9878), Valid: (LOSS: 0.0371, MAE: 0.0371, RMSE: 0.0554, R2: 0.9528), PNorm: 137.6323, GNorm: 1.0526
[180/299] timecost: 63.65, lr: 0.000027, Train: (LOSS: 0.0157, MAE: 0.0157, RMSE: 0.0256, R2: 0.9878), Valid: (LOSS: 0.0360, MAE: 0.0360, RMSE: 0.0547, R2: 0.9544), PNorm: 137.5340, GNorm: 0.9042
[181/299] timecost: 63.69, lr: 0.000027, Train: (LOSS: 0.0153, MAE: 0.0153, RMSE: 0.0249, R2: 0.9884), Valid: (LOSS: 0.0345, MAE: 0.0345, RMSE: 0.0522, R2: 0.9585), PNorm: 137.4331, GNorm: 0.7461
[182/299] timecost: 63.51, lr: 0.000027, Train: (LOSS: 0.0147, MAE: 0.0147, RMSE: 0.0240, R2: 0.9894), Valid: (LOSS: 0.0354, MAE: 0.0354, RMSE: 0.0546, R2: 0.9551), PNorm: 137.3344, GNorm: 0.6516
[183/299] timecost: 64.61, lr: 0.000027, Train: (LOSS: 0.0145, MAE: 0.0145, RMSE: 0.0232, R2: 0.9889), Valid: (LOSS: 0.0363, MAE: 0.0363, RMSE: 0.0542, R2: 0.9547), PNorm: 137.2362, GNorm: 0.9318
[184/299] timecost: 63.37, lr: 0.000027, Train: (LOSS: 0.0147, MAE: 0.0147, RMSE: 0.0237, R2: 0.9897), Valid: (LOSS: 0.0362, MAE: 0.0362, RMSE: 0.0534, R2: 0.9561), PNorm: 137.1390, GNorm: 0.9325
[185/299] timecost: 62.75, lr: 0.000027, Train: (LOSS: 0.0141, MAE: 0.0141, RMSE: 0.0231, R2: 0.9892), Valid: (LOSS: 0.0356, MAE: 0.0356, RMSE: 0.0544, R2: 0.9552), PNorm: 137.0429, GNorm: 0.9457
[186/299] timecost: 62.50, lr: 0.000027, Train: (LOSS: 0.0146, MAE: 0.0146, RMSE: 0.0238, R2: 0.9889), Valid: (LOSS: 0.0351, MAE: 0.0351, RMSE: 0.0525, R2: 0.9581), PNorm: 136.9471, GNorm: 0.7300
[187/299] timecost: 62.58, lr: 0.000027, Train: (LOSS: 0.0143, MAE: 0.0143, RMSE: 0.0232, R2: 0.9881), Valid: (LOSS: 0.0372, MAE: 0.0372, RMSE: 0.0555, R2: 0.9533), PNorm: 136.8531, GNorm: 0.8706
[188/299] timecost: 63.19, lr: 0.000027, Train: (LOSS: 0.0149, MAE: 0.0149, RMSE: 0.0240, R2: 0.9892), Valid: (LOSS: 0.0373, MAE: 0.0373, RMSE: 0.0563, R2: 0.9521), PNorm: 136.7593, GNorm: 0.7238
[189/299] timecost: 63.02, lr: 0.000027, Train: (LOSS: 0.0155, MAE: 0.0155, RMSE: 0.0245, R2: 0.9893), Valid: (LOSS: 0.0371, MAE: 0.0371, RMSE: 0.0541, R2: 0.9560), PNorm: 136.6675, GNorm: 1.2344
[190/299] timecost: 63.06, lr: 0.000027, Train: (LOSS: 0.0144, MAE: 0.0144, RMSE: 0.0237, R2: 0.9895), Valid: (LOSS: 0.0351, MAE: 0.0351, RMSE: 0.0520, R2: 0.9593), PNorm: 136.5754, GNorm: 0.8264
[191/299] timecost: 62.74, lr: 0.000027, Train: (LOSS: 0.0137, MAE: 0.0137, RMSE: 0.0228, R2: 0.9897), Valid: (LOSS: 0.0354, MAE: 0.0354, RMSE: 0.0540, R2: 0.9555), PNorm: 136.4841, GNorm: 0.7282
[192/299] timecost: 63.03, lr: 0.000027, Train: (LOSS: 0.0141, MAE: 0.0141, RMSE: 0.0229, R2: 0.9898), Valid: (LOSS: 0.0342, MAE: 0.0342, RMSE: 0.0521, R2: 0.9590), PNorm: 136.3933, GNorm: 0.6255
[193/299] timecost: 62.70, lr: 0.000027, Train: (LOSS: 0.0138, MAE: 0.0138, RMSE: 0.0223, R2: 0.9905), Valid: (LOSS: 0.0345, MAE: 0.0345, RMSE: 0.0511, R2: 0.9600), PNorm: 136.3034, GNorm: 0.9429
[194/299] timecost: 62.71, lr: 0.000027, Train: (LOSS: 0.0137, MAE: 0.0137, RMSE: 0.0225, R2: 0.9902), Valid: (LOSS: 0.0381, MAE: 0.0381, RMSE: 0.0560, R2: 0.9521), PNorm: 136.2131, GNorm: 0.7981
Epoch 00196: reducing learning rate of group 0 to 2.4300e-05.
[195/299] timecost: 62.59, lr: 0.000024, Train: (LOSS: 0.0144, MAE: 0.0144, RMSE: 0.0231, R2: 0.9893), Valid: (LOSS: 0.0335, MAE: 0.0335, RMSE: 0.0507, R2: 0.9608), PNorm: 136.1249, GNorm: 0.6934
[196/299] timecost: 63.18, lr: 0.000024, Train: (LOSS: 0.0138, MAE: 0.0138, RMSE: 0.0224, R2: 0.9906), Valid: (LOSS: 0.0350, MAE: 0.0350, RMSE: 0.0535, R2: 0.9556), PNorm: 136.0457, GNorm: 0.7580
[197/299] timecost: 62.92, lr: 0.000024, Train: (LOSS: 0.0129, MAE: 0.0129, RMSE: 0.0210, R2: 0.9906), Valid: (LOSS: 0.0348, MAE: 0.0348, RMSE: 0.0527, R2: 0.9584), PNorm: 135.9656, GNorm: 0.8843
[198/299] timecost: 62.91, lr: 0.000024, Train: (LOSS: 0.0129, MAE: 0.0129, RMSE: 0.0213, R2: 0.9914), Valid: (LOSS: 0.0363, MAE: 0.0363, RMSE: 0.0538, R2: 0.9560), PNorm: 135.8873, GNorm: 0.7521
[199/299] timecost: 63.00, lr: 0.000024, Train: (LOSS: 0.0125, MAE: 0.0125, RMSE: 0.0208, R2: 0.9916), Valid: (LOSS: 0.0359, MAE: 0.0359, RMSE: 0.0536, R2: 0.9563), PNorm: 135.8082, GNorm: 0.9326
[200/299] timecost: 63.03, lr: 0.000024, Train: (LOSS: 0.0126, MAE: 0.0126, RMSE: 0.0208, R2: 0.9916), Valid: (LOSS: 0.0352, MAE: 0.0352, RMSE: 0.0531, R2: 0.9564), PNorm: 135.7295, GNorm: 0.8684
[201/299] timecost: 63.43, lr: 0.000024, Train: (LOSS: 0.0123, MAE: 0.0123, RMSE: 0.0201, R2: 0.9920), Valid: (LOSS: 0.0355, MAE: 0.0355, RMSE: 0.0539, R2: 0.9555), PNorm: 135.6505, GNorm: 0.9269
[202/299] timecost: 64.26, lr: 0.000024, Train: (LOSS: 0.0128, MAE: 0.0128, RMSE: 0.0210, R2: 0.9917), Valid: (LOSS: 0.0349, MAE: 0.0349, RMSE: 0.0540, R2: 0.9550), PNorm: 135.5724, GNorm: 1.0617
[203/299] timecost: 63.35, lr: 0.000024, Train: (LOSS: 0.0129, MAE: 0.0129, RMSE: 0.0206, R2: 0.9915), Valid: (LOSS: 0.0348, MAE: 0.0348, RMSE: 0.0529, R2: 0.9567), PNorm: 135.4946, GNorm: 0.8608
[204/299] timecost: 62.85, lr: 0.000024, Train: (LOSS: 0.0132, MAE: 0.0132, RMSE: 0.0210, R2: 0.9910), Valid: (LOSS: 0.0350, MAE: 0.0350, RMSE: 0.0517, R2: 0.9592), PNorm: 135.4160, GNorm: 0.9725
[205/299] timecost: 62.83, lr: 0.000024, Train: (LOSS: 0.0125, MAE: 0.0125, RMSE: 0.0207, R2: 0.9917), Valid: (LOSS: 0.0352, MAE: 0.0352, RMSE: 0.0522, R2: 0.9589), PNorm: 135.3387, GNorm: 0.7664
[206/299] timecost: 62.59, lr: 0.000024, Train: (LOSS: 0.0124, MAE: 0.0124, RMSE: 0.0204, R2: 0.9915), Valid: (LOSS: 0.0332, MAE: 0.0332, RMSE: 0.0490, R2: 0.9637), PNorm: 135.2616, GNorm: 0.7919
[207/299] timecost: 62.92, lr: 0.000024, Train: (LOSS: 0.0124, MAE: 0.0124, RMSE: 0.0200, R2: 0.9922), Valid: (LOSS: 0.0340, MAE: 0.0340, RMSE: 0.0509, R2: 0.9605), PNorm: 135.1845, GNorm: 1.0984
[208/299] timecost: 62.53, lr: 0.000024, Train: (LOSS: 0.0126, MAE: 0.0126, RMSE: 0.0202, R2: 0.9913), Valid: (LOSS: 0.0338, MAE: 0.0338, RMSE: 0.0506, R2: 0.9610), PNorm: 135.1087, GNorm: 0.7107
[209/299] timecost: 62.66, lr: 0.000024, Train: (LOSS: 0.0127, MAE: 0.0127, RMSE: 0.0206, R2: 0.9919), Valid: (LOSS: 0.0354, MAE: 0.0354, RMSE: 0.0521, R2: 0.9587), PNorm: 135.0330, GNorm: 0.6680
[210/299] timecost: 62.85, lr: 0.000024, Train: (LOSS: 0.0123, MAE: 0.0123, RMSE: 0.0202, R2: 0.9921), Valid: (LOSS: 0.0346, MAE: 0.0346, RMSE: 0.0525, R2: 0.9579), PNorm: 134.9566, GNorm: 1.0895
[211/299] timecost: 63.17, lr: 0.000024, Train: (LOSS: 0.0120, MAE: 0.0120, RMSE: 0.0194, R2: 0.9927), Valid: (LOSS: 0.0356, MAE: 0.0356, RMSE: 0.0514, R2: 0.9596), PNorm: 134.8806, GNorm: 0.7517
[212/299] timecost: 62.98, lr: 0.000024, Train: (LOSS: 0.0127, MAE: 0.0127, RMSE: 0.0206, R2: 0.9916), Valid: (LOSS: 0.0354, MAE: 0.0354, RMSE: 0.0537, R2: 0.9553), PNorm: 134.8054, GNorm: 0.9875
[213/299] timecost: 63.06, lr: 0.000024, Train: (LOSS: 0.0122, MAE: 0.0122, RMSE: 0.0196, R2: 0.9923), Valid: (LOSS: 0.0353, MAE: 0.0353, RMSE: 0.0528, R2: 0.9576), PNorm: 134.7298, GNorm: 0.8688
[214/299] timecost: 64.26, lr: 0.000024, Train: (LOSS: 0.0124, MAE: 0.0124, RMSE: 0.0199, R2: 0.9924), Valid: (LOSS: 0.0333, MAE: 0.0333, RMSE: 0.0499, R2: 0.9623), PNorm: 134.6550, GNorm: 0.6441
[215/299] timecost: 63.06, lr: 0.000024, Train: (LOSS: 0.0123, MAE: 0.0123, RMSE: 0.0195, R2: 0.9931), Valid: (LOSS: 0.0335, MAE: 0.0335, RMSE: 0.0488, R2: 0.9634), PNorm: 134.5808, GNorm: 0.7604
[216/299] timecost: 62.59, lr: 0.000024, Train: (LOSS: 0.0116, MAE: 0.0116, RMSE: 0.0186, R2: 0.9936), Valid: (LOSS: 0.0338, MAE: 0.0338, RMSE: 0.0503, R2: 0.9610), PNorm: 134.5052, GNorm: 0.8663
[217/299] timecost: 63.34, lr: 0.000024, Train: (LOSS: 0.0110, MAE: 0.0110, RMSE: 0.0181, R2: 0.9938), Valid: (LOSS: 0.0341, MAE: 0.0341, RMSE: 0.0503, R2: 0.9613), PNorm: 134.4303, GNorm: 0.8824
[218/299] timecost: 63.92, lr: 0.000024, Train: (LOSS: 0.0116, MAE: 0.0116, RMSE: 0.0187, R2: 0.9935), Valid: (LOSS: 0.0346, MAE: 0.0346, RMSE: 0.0521, R2: 0.9584), PNorm: 134.3559, GNorm: 0.7068
[219/299] timecost: 62.93, lr: 0.000024, Train: (LOSS: 0.0118, MAE: 0.0118, RMSE: 0.0186, R2: 0.9935), Valid: (LOSS: 0.0353, MAE: 0.0353, RMSE: 0.0512, R2: 0.9591), PNorm: 134.2818, GNorm: 0.8347
[220/299] timecost: 64.20, lr: 0.000024, Train: (LOSS: 0.0115, MAE: 0.0115, RMSE: 0.0187, R2: 0.9936), Valid: (LOSS: 0.0328, MAE: 0.0328, RMSE: 0.0496, R2: 0.9619), PNorm: 134.2074, GNorm: 0.8793
[221/299] timecost: 64.89, lr: 0.000024, Train: (LOSS: 0.0114, MAE: 0.0114, RMSE: 0.0180, R2: 0.9939), Valid: (LOSS: 0.0343, MAE: 0.0343, RMSE: 0.0503, R2: 0.9606), PNorm: 134.1336, GNorm: 0.8803
[222/299] timecost: 64.24, lr: 0.000024, Train: (LOSS: 0.0116, MAE: 0.0116, RMSE: 0.0183, R2: 0.9934), Valid: (LOSS: 0.0356, MAE: 0.0356, RMSE: 0.0522, R2: 0.9573), PNorm: 134.0601, GNorm: 0.7111
[223/299] timecost: 63.92, lr: 0.000024, Train: (LOSS: 0.0114, MAE: 0.0114, RMSE: 0.0185, R2: 0.9936), Valid: (LOSS: 0.0333, MAE: 0.0333, RMSE: 0.0485, R2: 0.9628), PNorm: 133.9859, GNorm: 0.8617
[224/299] timecost: 64.25, lr: 0.000024, Train: (LOSS: 0.0112, MAE: 0.0112, RMSE: 0.0179, R2: 0.9940), Valid: (LOSS: 0.0331, MAE: 0.0331, RMSE: 0.0495, R2: 0.9621), PNorm: 133.9122, GNorm: 0.9479
[225/299] timecost: 63.93, lr: 0.000024, Train: (LOSS: 0.0115, MAE: 0.0115, RMSE: 0.0185, R2: 0.9937), Valid: (LOSS: 0.0331, MAE: 0.0331, RMSE: 0.0497, R2: 0.9612), PNorm: 133.8395, GNorm: 0.9117
[226/299] timecost: 64.01, lr: 0.000024, Train: (LOSS: 0.0114, MAE: 0.0114, RMSE: 0.0182, R2: 0.9930), Valid: (LOSS: 0.0351, MAE: 0.0351, RMSE: 0.0510, R2: 0.9593), PNorm: 133.7659, GNorm: 0.8254
[227/299] timecost: 64.06, lr: 0.000024, Train: (LOSS: 0.0116, MAE: 0.0116, RMSE: 0.0184, R2: 0.9939), Valid: (LOSS: 0.0352, MAE: 0.0352, RMSE: 0.0514, R2: 0.9587), PNorm: 133.6932, GNorm: 0.7622
[228/299] timecost: 62.86, lr: 0.000024, Train: (LOSS: 0.0114, MAE: 0.0114, RMSE: 0.0178, R2: 0.9939), Valid: (LOSS: 0.0349, MAE: 0.0349, RMSE: 0.0501, R2: 0.9610), PNorm: 133.6206, GNorm: 0.7920
[229/299] timecost: 63.21, lr: 0.000024, Train: (LOSS: 0.0116, MAE: 0.0116, RMSE: 0.0182, R2: 0.9940), Valid: (LOSS: 0.0340, MAE: 0.0340, RMSE: 0.0489, R2: 0.9631), PNorm: 133.5475, GNorm: 0.7881
[230/299] timecost: 63.20, lr: 0.000024, Train: (LOSS: 0.0116, MAE: 0.0116, RMSE: 0.0183, R2: 0.9939), Valid: (LOSS: 0.0342, MAE: 0.0342, RMSE: 0.0512, R2: 0.9595), PNorm: 133.4753, GNorm: 0.9134
[231/299] timecost: 62.39, lr: 0.000024, Train: (LOSS: 0.0112, MAE: 0.0112, RMSE: 0.0171, R2: 0.9948), Valid: (LOSS: 0.0333, MAE: 0.0333, RMSE: 0.0495, R2: 0.9622), PNorm: 133.4030, GNorm: 0.5603
[232/299] timecost: 63.00, lr: 0.000024, Train: (LOSS: 0.0105, MAE: 0.0105, RMSE: 0.0171, R2: 0.9942), Valid: (LOSS: 0.0334, MAE: 0.0334, RMSE: 0.0500, R2: 0.9611), PNorm: 133.3301, GNorm: 0.7993
[233/299] timecost: 63.99, lr: 0.000024, Train: (LOSS: 0.0114, MAE: 0.0114, RMSE: 0.0181, R2: 0.9943), Valid: (LOSS: 0.0347, MAE: 0.0347, RMSE: 0.0512, R2: 0.9590), PNorm: 133.2578, GNorm: 0.8044
[234/299] timecost: 63.16, lr: 0.000024, Train: (LOSS: 0.0111, MAE: 0.0111, RMSE: 0.0174, R2: 0.9947), Valid: (LOSS: 0.0336, MAE: 0.0336, RMSE: 0.0502, R2: 0.9613), PNorm: 133.1858, GNorm: 0.9759
[235/299] timecost: 62.95, lr: 0.000024, Train: (LOSS: 0.0107, MAE: 0.0107, RMSE: 0.0170, R2: 0.9941), Valid: (LOSS: 0.0323, MAE: 0.0323, RMSE: 0.0476, R2: 0.9648), PNorm: 133.1131, GNorm: 0.8723
[236/299] timecost: 63.13, lr: 0.000024, Train: (LOSS: 0.0112, MAE: 0.0112, RMSE: 0.0175, R2: 0.9944), Valid: (LOSS: 0.0354, MAE: 0.0354, RMSE: 0.0512, R2: 0.9585), PNorm: 133.0410, GNorm: 0.7863
[237/299] timecost: 63.17, lr: 0.000024, Train: (LOSS: 0.0108, MAE: 0.0108, RMSE: 0.0170, R2: 0.9949), Valid: (LOSS: 0.0321, MAE: 0.0321, RMSE: 0.0464, R2: 0.9660), PNorm: 132.9695, GNorm: 0.8810
[238/299] timecost: 62.90, lr: 0.000024, Train: (LOSS: 0.0108, MAE: 0.0108, RMSE: 0.0171, R2: 0.9941), Valid: (LOSS: 0.0341, MAE: 0.0341, RMSE: 0.0497, R2: 0.9612), PNorm: 132.8976, GNorm: 0.7589
[239/299] timecost: 63.02, lr: 0.000024, Train: (LOSS: 0.0111, MAE: 0.0111, RMSE: 0.0174, R2: 0.9946), Valid: (LOSS: 0.0337, MAE: 0.0337, RMSE: 0.0486, R2: 0.9631), PNorm: 132.8266, GNorm: 0.8611
[240/299] timecost: 63.15, lr: 0.000024, Train: (LOSS: 0.0108, MAE: 0.0108, RMSE: 0.0168, R2: 0.9942), Valid: (LOSS: 0.0332, MAE: 0.0332, RMSE: 0.0468, R2: 0.9643), PNorm: 132.7538, GNorm: 0.7863
[241/299] timecost: 63.81, lr: 0.000024, Train: (LOSS: 0.0103, MAE: 0.0103, RMSE: 0.0162, R2: 0.9945), Valid: (LOSS: 0.0337, MAE: 0.0337, RMSE: 0.0483, R2: 0.9633), PNorm: 132.6823, GNorm: 0.6050
[242/299] timecost: 64.23, lr: 0.000024, Train: (LOSS: 0.0105, MAE: 0.0105, RMSE: 0.0165, R2: 0.9945), Valid: (LOSS: 0.0336, MAE: 0.0336, RMSE: 0.0487, R2: 0.9626), PNorm: 132.6106, GNorm: 0.6547
[243/299] timecost: 63.96, lr: 0.000024, Train: (LOSS: 0.0123, MAE: 0.0123, RMSE: 0.0194, R2: 0.9934), Valid: (LOSS: 0.0338, MAE: 0.0338, RMSE: 0.0486, R2: 0.9625), PNorm: 132.5407, GNorm: 0.6184
[244/299] timecost: 64.03, lr: 0.000024, Train: (LOSS: 0.0106, MAE: 0.0106, RMSE: 0.0164, R2: 0.9947), Valid: (LOSS: 0.0327, MAE: 0.0327, RMSE: 0.0477, R2: 0.9645), PNorm: 132.4697, GNorm: 0.7214
[245/299] timecost: 62.97, lr: 0.000024, Train: (LOSS: 0.0104, MAE: 0.0104, RMSE: 0.0161, R2: 0.9952), Valid: (LOSS: 0.0329, MAE: 0.0329, RMSE: 0.0492, R2: 0.9616), PNorm: 132.3986, GNorm: 0.7731
[246/299] timecost: 63.60, lr: 0.000024, Train: (LOSS: 0.0103, MAE: 0.0103, RMSE: 0.0157, R2: 0.9951), Valid: (LOSS: 0.0306, MAE: 0.0306, RMSE: 0.0452, R2: 0.9680), PNorm: 132.3281, GNorm: 1.0090
[247/299] timecost: 63.76, lr: 0.000024, Train: (LOSS: 0.0107, MAE: 0.0107, RMSE: 0.0167, R2: 0.9949), Valid: (LOSS: 0.0329, MAE: 0.0329, RMSE: 0.0474, R2: 0.9655), PNorm: 132.2567, GNorm: 0.8692
[248/299] timecost: 64.07, lr: 0.000024, Train: (LOSS: 0.0106, MAE: 0.0106, RMSE: 0.0165, R2: 0.9951), Valid: (LOSS: 0.0330, MAE: 0.0330, RMSE: 0.0495, R2: 0.9607), PNorm: 132.1864, GNorm: 1.3723
[249/299] timecost: 63.07, lr: 0.000024, Train: (LOSS: 0.0106, MAE: 0.0106, RMSE: 0.0165, R2: 0.9949), Valid: (LOSS: 0.0336, MAE: 0.0336, RMSE: 0.0489, R2: 0.9623), PNorm: 132.1157, GNorm: 0.8394
[250/299] timecost: 63.10, lr: 0.000024, Train: (LOSS: 0.0105, MAE: 0.0105, RMSE: 0.0162, R2: 0.9952), Valid: (LOSS: 0.0350, MAE: 0.0350, RMSE: 0.0513, R2: 0.9587), PNorm: 132.0450, GNorm: 0.6798
[251/299] timecost: 63.25, lr: 0.000024, Train: (LOSS: 0.0105, MAE: 0.0105, RMSE: 0.0161, R2: 0.9950), Valid: (LOSS: 0.0339, MAE: 0.0339, RMSE: 0.0493, R2: 0.9622), PNorm: 131.9747, GNorm: 0.6964
[252/299] timecost: 63.10, lr: 0.000024, Train: (LOSS: 0.0111, MAE: 0.0111, RMSE: 0.0170, R2: 0.9947), Valid: (LOSS: 0.0335, MAE: 0.0335, RMSE: 0.0476, R2: 0.9647), PNorm: 131.9054, GNorm: 0.6561
[253/299] timecost: 63.51, lr: 0.000024, Train: (LOSS: 0.0103, MAE: 0.0103, RMSE: 0.0161, R2: 0.9950), Valid: (LOSS: 0.0342, MAE: 0.0342, RMSE: 0.0494, R2: 0.9610), PNorm: 131.8350, GNorm: 0.7583
[254/299] timecost: 63.71, lr: 0.000024, Train: (LOSS: 0.0099, MAE: 0.0099, RMSE: 0.0155, R2: 0.9954), Valid: (LOSS: 0.0352, MAE: 0.0352, RMSE: 0.0513, R2: 0.9582), PNorm: 131.7645, GNorm: 0.7460
[255/299] timecost: 64.14, lr: 0.000024, Train: (LOSS: 0.0101, MAE: 0.0101, RMSE: 0.0159, R2: 0.9948), Valid: (LOSS: 0.0329, MAE: 0.0329, RMSE: 0.0480, R2: 0.9639), PNorm: 131.6951, GNorm: 0.8253
[256/299] timecost: 64.04, lr: 0.000024, Train: (LOSS: 0.0099, MAE: 0.0099, RMSE: 0.0155, R2: 0.9957), Valid: (LOSS: 0.0337, MAE: 0.0337, RMSE: 0.0498, R2: 0.9609), PNorm: 131.6249, GNorm: 0.7087
[257/299] timecost: 64.06, lr: 0.000024, Train: (LOSS: 0.0105, MAE: 0.0105, RMSE: 0.0162, R2: 0.9952), Valid: (LOSS: 0.0346, MAE: 0.0346, RMSE: 0.0506, R2: 0.9605), PNorm: 131.5556, GNorm: 1.0848
[258/299] timecost: 64.28, lr: 0.000024, Train: (LOSS: 0.0102, MAE: 0.0102, RMSE: 0.0159, R2: 0.9954), Valid: (LOSS: 0.0335, MAE: 0.0335, RMSE: 0.0496, R2: 0.9611), PNorm: 131.4850, GNorm: 0.5993
[259/299] timecost: 64.27, lr: 0.000024, Train: (LOSS: 0.0097, MAE: 0.0097, RMSE: 0.0154, R2: 0.9952), Valid: (LOSS: 0.0330, MAE: 0.0330, RMSE: 0.0479, R2: 0.9639), PNorm: 131.4159, GNorm: 0.6961
[260/299] timecost: 62.95, lr: 0.000024, Train: (LOSS: 0.0096, MAE: 0.0096, RMSE: 0.0149, R2: 0.9957), Valid: (LOSS: 0.0342, MAE: 0.0342, RMSE: 0.0485, R2: 0.9631), PNorm: 131.3461, GNorm: 0.8074
[261/299] timecost: 62.79, lr: 0.000024, Train: (LOSS: 0.0100, MAE: 0.0100, RMSE: 0.0154, R2: 0.9954), Valid: (LOSS: 0.0346, MAE: 0.0346, RMSE: 0.0508, R2: 0.9594), PNorm: 131.2764, GNorm: 1.1662
[262/299] timecost: 64.20, lr: 0.000024, Train: (LOSS: 0.0095, MAE: 0.0095, RMSE: 0.0148, R2: 0.9958), Valid: (LOSS: 0.0327, MAE: 0.0327, RMSE: 0.0494, R2: 0.9603), PNorm: 131.2068, GNorm: 0.8903
[263/299] timecost: 64.59, lr: 0.000024, Train: (LOSS: 0.0095, MAE: 0.0095, RMSE: 0.0147, R2: 0.9960), Valid: (LOSS: 0.0328, MAE: 0.0328, RMSE: 0.0471, R2: 0.9655), PNorm: 131.1379, GNorm: 0.8500
[264/299] timecost: 64.22, lr: 0.000024, Train: (LOSS: 0.0095, MAE: 0.0095, RMSE: 0.0148, R2: 0.9959), Valid: (LOSS: 0.0332, MAE: 0.0332, RMSE: 0.0486, R2: 0.9626), PNorm: 131.0678, GNorm: 0.7768
[265/299] timecost: 63.89, lr: 0.000024, Train: (LOSS: 0.0099, MAE: 0.0099, RMSE: 0.0153, R2: 0.9956), Valid: (LOSS: 0.0339, MAE: 0.0339, RMSE: 0.0487, R2: 0.9633), PNorm: 130.9991, GNorm: 0.5796
[266/299] timecost: 63.97, lr: 0.000024, Train: (LOSS: 0.0098, MAE: 0.0098, RMSE: 0.0150, R2: 0.9960), Valid: (LOSS: 0.0339, MAE: 0.0339, RMSE: 0.0502, R2: 0.9607), PNorm: 130.9299, GNorm: 0.7604
Epoch 00268: reducing learning rate of group 0 to 2.1870e-05.
[267/299] timecost: 63.53, lr: 0.000022, Train: (LOSS: 0.0097, MAE: 0.0097, RMSE: 0.0151, R2: 0.9956), Valid: (LOSS: 0.0336, MAE: 0.0336, RMSE: 0.0495, R2: 0.9616), PNorm: 130.8598, GNorm: 0.9682
[268/299] timecost: 63.87, lr: 0.000022, Train: (LOSS: 0.0094, MAE: 0.0094, RMSE: 0.0147, R2: 0.9958), Valid: (LOSS: 0.0326, MAE: 0.0326, RMSE: 0.0486, R2: 0.9630), PNorm: 130.7982, GNorm: 0.7591
[269/299] timecost: 63.45, lr: 0.000022, Train: (LOSS: 0.0092, MAE: 0.0092, RMSE: 0.0143, R2: 0.9960), Valid: (LOSS: 0.0328, MAE: 0.0328, RMSE: 0.0482, R2: 0.9634), PNorm: 130.7352, GNorm: 0.7288
[270/299] timecost: 63.44, lr: 0.000022, Train: (LOSS: 0.0090, MAE: 0.0090, RMSE: 0.0141, R2: 0.9962), Valid: (LOSS: 0.0325, MAE: 0.0325, RMSE: 0.0467, R2: 0.9657), PNorm: 130.6730, GNorm: 0.5218
[271/299] timecost: 63.47, lr: 0.000022, Train: (LOSS: 0.0089, MAE: 0.0089, RMSE: 0.0140, R2: 0.9961), Valid: (LOSS: 0.0333, MAE: 0.0333, RMSE: 0.0496, R2: 0.9610), PNorm: 130.6102, GNorm: 0.7969
[272/299] timecost: 63.80, lr: 0.000022, Train: (LOSS: 0.0088, MAE: 0.0088, RMSE: 0.0137, R2: 0.9966), Valid: (LOSS: 0.0330, MAE: 0.0330, RMSE: 0.0480, R2: 0.9641), PNorm: 130.5473, GNorm: 0.9032
[273/299] timecost: 63.74, lr: 0.000022, Train: (LOSS: 0.0097, MAE: 0.0097, RMSE: 0.0147, R2: 0.9961), Valid: (LOSS: 0.0339, MAE: 0.0339, RMSE: 0.0488, R2: 0.9627), PNorm: 130.4857, GNorm: 0.7847
[274/299] timecost: 63.36, lr: 0.000022, Train: (LOSS: 0.0093, MAE: 0.0093, RMSE: 0.0140, R2: 0.9957), Valid: (LOSS: 0.0340, MAE: 0.0340, RMSE: 0.0494, R2: 0.9617), PNorm: 130.4229, GNorm: 0.7339
[275/299] timecost: 63.84, lr: 0.000022, Train: (LOSS: 0.0092, MAE: 0.0092, RMSE: 0.0143, R2: 0.9960), Valid: (LOSS: 0.0329, MAE: 0.0329, RMSE: 0.0482, R2: 0.9639), PNorm: 130.3613, GNorm: 0.7951
[276/299] timecost: 63.51, lr: 0.000022, Train: (LOSS: 0.0088, MAE: 0.0088, RMSE: 0.0137, R2: 0.9964), Valid: (LOSS: 0.0321, MAE: 0.0321, RMSE: 0.0466, R2: 0.9654), PNorm: 130.2992, GNorm: 0.5768
[277/299] timecost: 63.71, lr: 0.000022, Train: (LOSS: 0.0085, MAE: 0.0085, RMSE: 0.0133, R2: 0.9965), Valid: (LOSS: 0.0343, MAE: 0.0343, RMSE: 0.0497, R2: 0.9610), PNorm: 130.2372, GNorm: 0.7763
[278/299] timecost: 63.73, lr: 0.000022, Train: (LOSS: 0.0087, MAE: 0.0087, RMSE: 0.0138, R2: 0.9963), Valid: (LOSS: 0.0331, MAE: 0.0331, RMSE: 0.0484, R2: 0.9636), PNorm: 130.1743, GNorm: 0.5564
[279/299] timecost: 63.72, lr: 0.000022, Train: (LOSS: 0.0088, MAE: 0.0088, RMSE: 0.0136, R2: 0.9965), Valid: (LOSS: 0.0349, MAE: 0.0349, RMSE: 0.0503, R2: 0.9600), PNorm: 130.1121, GNorm: 0.8005
[280/299] timecost: 63.50, lr: 0.000022, Train: (LOSS: 0.0092, MAE: 0.0092, RMSE: 0.0142, R2: 0.9962), Valid: (LOSS: 0.0335, MAE: 0.0335, RMSE: 0.0485, R2: 0.9620), PNorm: 130.0504, GNorm: 0.7183
[281/299] timecost: 63.74, lr: 0.000022, Train: (LOSS: 0.0088, MAE: 0.0088, RMSE: 0.0136, R2: 0.9964), Valid: (LOSS: 0.0318, MAE: 0.0318, RMSE: 0.0470, R2: 0.9652), PNorm: 129.9877, GNorm: 0.7537
[282/299] timecost: 63.53, lr: 0.000022, Train: (LOSS: 0.0084, MAE: 0.0084, RMSE: 0.0132, R2: 0.9966), Valid: (LOSS: 0.0344, MAE: 0.0344, RMSE: 0.0499, R2: 0.9603), PNorm: 129.9257, GNorm: 0.5582
[283/299] timecost: 63.30, lr: 0.000022, Train: (LOSS: 0.0084, MAE: 0.0084, RMSE: 0.0133, R2: 0.9963), Valid: (LOSS: 0.0322, MAE: 0.0322, RMSE: 0.0460, R2: 0.9664), PNorm: 129.8632, GNorm: 0.5314
[284/299] timecost: 63.94, lr: 0.000022, Train: (LOSS: 0.0085, MAE: 0.0085, RMSE: 0.0133, R2: 0.9964), Valid: (LOSS: 0.0336, MAE: 0.0336, RMSE: 0.0491, R2: 0.9623), PNorm: 129.8018, GNorm: 0.6076
[285/299] timecost: 63.45, lr: 0.000022, Train: (LOSS: 0.0084, MAE: 0.0084, RMSE: 0.0131, R2: 0.9967), Valid: (LOSS: 0.0330, MAE: 0.0330, RMSE: 0.0485, R2: 0.9630), PNorm: 129.7396, GNorm: 0.5650
[286/299] timecost: 63.36, lr: 0.000022, Train: (LOSS: 0.0083, MAE: 0.0083, RMSE: 0.0130, R2: 0.9968), Valid: (LOSS: 0.0335, MAE: 0.0335, RMSE: 0.0490, R2: 0.9617), PNorm: 129.6777, GNorm: 1.0120
[287/299] timecost: 63.77, lr: 0.000022, Train: (LOSS: 0.0085, MAE: 0.0085, RMSE: 0.0132, R2: 0.9965), Valid: (LOSS: 0.0323, MAE: 0.0323, RMSE: 0.0471, R2: 0.9654), PNorm: 129.6154, GNorm: 0.6792
Epoch 00289: reducing learning rate of group 0 to 1.9683e-05.
[288/299] timecost: 63.61, lr: 0.000020, Train: (LOSS: 0.0084, MAE: 0.0084, RMSE: 0.0131, R2: 0.9966), Valid: (LOSS: 0.0325, MAE: 0.0325, RMSE: 0.0470, R2: 0.9657), PNorm: 129.5536, GNorm: 0.9301
[289/299] timecost: 63.51, lr: 0.000020, Train: (LOSS: 0.0082, MAE: 0.0082, RMSE: 0.0129, R2: 0.9968), Valid: (LOSS: 0.0326, MAE: 0.0326, RMSE: 0.0480, R2: 0.9637), PNorm: 129.4976, GNorm: 0.6686
[290/299] timecost: 63.85, lr: 0.000020, Train: (LOSS: 0.0078, MAE: 0.0078, RMSE: 0.0122, R2: 0.9969), Valid: (LOSS: 0.0332, MAE: 0.0332, RMSE: 0.0478, R2: 0.9642), PNorm: 129.4413, GNorm: 0.6978
[291/299] timecost: 63.48, lr: 0.000020, Train: (LOSS: 0.0081, MAE: 0.0081, RMSE: 0.0129, R2: 0.9966), Valid: (LOSS: 0.0326, MAE: 0.0326, RMSE: 0.0465, R2: 0.9659), PNorm: 129.3862, GNorm: 0.8225
[292/299] timecost: 63.55, lr: 0.000020, Train: (LOSS: 0.0080, MAE: 0.0080, RMSE: 0.0126, R2: 0.9970), Valid: (LOSS: 0.0340, MAE: 0.0340, RMSE: 0.0495, R2: 0.9610), PNorm: 129.3299, GNorm: 0.7073
[293/299] timecost: 62.63, lr: 0.000020, Train: (LOSS: 0.0075, MAE: 0.0075, RMSE: 0.0122, R2: 0.9972), Valid: (LOSS: 0.0319, MAE: 0.0319, RMSE: 0.0466, R2: 0.9660), PNorm: 129.2739, GNorm: 0.8214
[294/299] timecost: 63.38, lr: 0.000020, Train: (LOSS: 0.0079, MAE: 0.0079, RMSE: 0.0121, R2: 0.9970), Valid: (LOSS: 0.0318, MAE: 0.0318, RMSE: 0.0458, R2: 0.9670), PNorm: 129.2181, GNorm: 0.6874
[295/299] timecost: 63.31, lr: 0.000020, Train: (LOSS: 0.0078, MAE: 0.0078, RMSE: 0.0121, R2: 0.9970), Valid: (LOSS: 0.0329, MAE: 0.0329, RMSE: 0.0479, R2: 0.9636), PNorm: 129.1621, GNorm: 0.5916
[296/299] timecost: 63.87, lr: 0.000020, Train: (LOSS: 0.0077, MAE: 0.0077, RMSE: 0.0121, R2: 0.9971), Valid: (LOSS: 0.0323, MAE: 0.0323, RMSE: 0.0479, R2: 0.9634), PNorm: 129.1059, GNorm: 0.7116
[297/299] timecost: 63.27, lr: 0.000020, Train: (LOSS: 0.0077, MAE: 0.0077, RMSE: 0.0121, R2: 0.9971), Valid: (LOSS: 0.0328, MAE: 0.0328, RMSE: 0.0476, R2: 0.9640), PNorm: 129.0500, GNorm: 0.9759
[298/299] timecost: 63.47, lr: 0.000020, Train: (LOSS: 0.0080, MAE: 0.0080, RMSE: 0.0126, R2: 0.9970), Valid: (LOSS: 0.0328, MAE: 0.0328, RMSE: 0.0485, R2: 0.9630), PNorm: 128.9941, GNorm: 0.6660
[299/299] timecost: 63.50, lr: 0.000020, Train: (LOSS: 0.0076, MAE: 0.0076, RMSE: 0.0119, R2: 0.9969), Valid: (LOSS: 0.0323, MAE: 0.0323, RMSE: 0.0471, R2: 0.9653), PNorm: 128.9382, GNorm: 0.6468
==========Training End==========
==========Test Best Model==========
================Final Results=======================
mse: 0.0364 +- 0.0000:
rmse: 0.0548 +- 0.0000:
mae: 0.0364 +- 0.0000:
r2: 0.9551 +- 0.0000:
tensor([[0.1133, 0.1066],
        [0.0000, 0.0000],
        [0.0000, 0.0000],
        ...,
        [0.0000, 0.0000],
        [0.0000, 0.0000],
        [0.0000, 0.0000]], device='cuda:0')
