{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/PCON0041/xiaohu/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Code based on:\n",
    "Shang et al \"Edge Attention-based Multi-Relational Graph Convolutional Networks\" -> https://github.com/Luckick/EAGCN\n",
    "Coley et al \"Convolutional Embedding of Attributed Molecular Graphs for Physical Property Prediction\" -> https://github.com/connorcoley/conv_qsar_fast\n",
    "\"\"\"\n",
    "import os\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "IntTensor = torch.cuda.IntTensor if use_cuda else torch.IntTensor\n",
    "DoubleTensor = torch.cuda.DoubleTensor if use_cuda else torch.DoubleTensor\n",
    "\n",
    "\n",
    "def load_data_from_smiles(smiles, add_dummy_node=True, one_hot_formal_charge=True):\n",
    "    \"\"\"Load and featurize data from lists of SMILES strings and labels.\n",
    "\n",
    "    Args:\n",
    "        x_smiles (list[str]): A list of SMILES strings.\n",
    "        labels (list[float]): A list of the corresponding labels.\n",
    "        add_dummy_node (bool): If True, a dummy node will be added to the molecular graph. Defaults to True.\n",
    "        one_hot_formal_charge (bool): If True, formal charges on atoms are one-hot encoded. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        A tuple (X, y) in which X is a list of graph descriptors (node features, adjacency matrices, distance matrices),\n",
    "        and y is a list of the corresponding labels.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        mol = MolFromSmiles(smiles)\n",
    "        try:\n",
    "            mol = Chem.AddHs(mol)\n",
    "            AllChem.EmbedMolecule(mol, maxAttempts=5000)\n",
    "            AllChem.UFFOptimizeMolecule(mol)\n",
    "            mol = Chem.RemoveHs(mol)\n",
    "        except:\n",
    "            AllChem.Compute2DCoords(mol)\n",
    "        afm, adj, dist = featurize_mol(mol, add_dummy_node, one_hot_formal_charge)\n",
    "\n",
    "    except ValueError as e:\n",
    "        print('the SMILES ({}) can not be converted to a graph.\\nREASON: {}'.format(smiles, e))\n",
    "\n",
    "    return afm, adj, dist\n",
    "\n",
    "\n",
    "def featurize_mol(mol, add_dummy_node, one_hot_formal_charge):\n",
    "    \"\"\"Featurize molecule.\n",
    "\n",
    "    Args:\n",
    "        mol (rdchem.Mol): An RDKit Mol object.\n",
    "        add_dummy_node (bool): If True, a dummy node will be added to the molecular graph.\n",
    "        one_hot_formal_charge (bool): If True, formal charges on atoms are one-hot encoded.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of molecular graph descriptors (node features, adjacency matrix, distance matrix).\n",
    "    \"\"\"\n",
    "    node_features = np.array([get_atom_features(atom, one_hot_formal_charge)\n",
    "                              for atom in mol.GetAtoms()])\n",
    "    #print(node_features.shape)\n",
    "    adj_matrix = np.eye(mol.GetNumAtoms())\n",
    "    for bond in mol.GetBonds():\n",
    "        begin_atom = bond.GetBeginAtom().GetIdx()\n",
    "        end_atom = bond.GetEndAtom().GetIdx()\n",
    "        adj_matrix[begin_atom, end_atom] = adj_matrix[end_atom, begin_atom] = 1\n",
    "\n",
    "    conf = mol.GetConformer()\n",
    "    pos_matrix = np.array([[conf.GetAtomPosition(k).x, conf.GetAtomPosition(k).y, conf.GetAtomPosition(k).z]\n",
    "                           for k in range(mol.GetNumAtoms())])\n",
    "    dist_matrix = pairwise_distances(pos_matrix)\n",
    "\n",
    "    if add_dummy_node:\n",
    "        m = np.zeros((node_features.shape[0] + 1, node_features.shape[1] + 1))\n",
    "        m[1:, 1:] = node_features\n",
    "        m[0, 0] = 1.\n",
    "        node_features = m\n",
    "\n",
    "        m = np.zeros((adj_matrix.shape[0] + 1, adj_matrix.shape[1] + 1))\n",
    "        m[1:, 1:] = adj_matrix\n",
    "        adj_matrix = m\n",
    "\n",
    "        m = np.full((dist_matrix.shape[0] + 1, dist_matrix.shape[1] + 1), 1e6)\n",
    "        m[1:, 1:] = dist_matrix\n",
    "        dist_matrix = m\n",
    "\n",
    "    return node_features, adj_matrix, dist_matrix\n",
    "\n",
    "\n",
    "def get_atom_features(atom, one_hot_formal_charge=True):\n",
    "    \"\"\"Calculate atom features.\n",
    "\n",
    "    Args:\n",
    "        atom (rdchem.Atom): An RDKit Atom object.\n",
    "        one_hot_formal_charge (bool): If True, formal charges on atoms are one-hot encoded.\n",
    "\n",
    "    Returns:\n",
    "        A 1-dimensional array (ndarray) of atom features.\n",
    "    \"\"\"\n",
    "    attributes = []\n",
    "\n",
    "    attributes += one_hot_vector(\n",
    "        atom.GetAtomicNum(),\n",
    "        #[6, 8, 7, 16, 35, 19, 53, 11, 17, 9, 15, 46, 5, 14, 55, 1, 13, 3, 26, 24, 22, 12, 25, 29,\n",
    "        # 44, 28, 78, 47, 30, 75, 56, 50, 27, 20, 34, 45, 58, 40, 80, 74, 70, 21, 999]\n",
    "        [5, 6, 7, 8, 9, 15, 16, 17, 35, 53, 999]\n",
    "        #[6, 7, 8, 9, 15, 16, 17, 35, 53]\n",
    "        #[9, 6, 17, 7, 15, 8, 35, 53, 16]\n",
    "    )\n",
    "\n",
    "    attributes += one_hot_vector(\n",
    "        len(atom.GetNeighbors()),\n",
    "        [0, 1, 2, 3, 4, 5]\n",
    "    )\n",
    "\n",
    "    attributes += one_hot_vector(\n",
    "        atom.GetTotalNumHs(),\n",
    "        [0, 1, 2, 3, 4]\n",
    "    )\n",
    "\n",
    "    if one_hot_formal_charge:\n",
    "        #print(one_hot_vector(atom.GetFormalCharge(),[-1, 0, 1]))\n",
    "        #attributes += one_hot_vector(atom.GetFormalCharge(),[-1, 0, 1, 999])\n",
    "        attributes += one_hot_vector(atom.GetFormalCharge(),[-1, 0, 1])\n",
    "    else:\n",
    "        attributes.append(atom.GetFormalCharge())\n",
    "\n",
    "    attributes.append(atom.IsInRing())\n",
    "    attributes.append(atom.GetIsAromatic())\n",
    "    return np.array(attributes, dtype=np.float32)\n",
    "\n",
    "\n",
    "def one_hot_vector(val, lst):\n",
    "    \"\"\"Converts a value to a one-hot vector based on options in lst\"\"\"\n",
    "    if val not in lst:\n",
    "        val = lst[-1]\n",
    "    return map(lambda x: x == val, lst)\n",
    "\n",
    "\n",
    "#dimension 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "400\n",
      "800\n",
      "1200\n",
      "1600\n",
      "2000\n",
      "2400\n",
      "2800\n",
      "3200\n",
      "3600\n",
      "7910\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./BH_processed.csv')\n",
    "from rdkit import RDLogger \n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "r_dic = []\n",
    "ri_list = []\n",
    "ri_afm_list = []\n",
    "ri_adj_list = []\n",
    "ri_dist_list = []\n",
    "reaction_index_list = []\n",
    "molecule_index_list = []\n",
    "ri_center_list = []\n",
    "yield_list = []\n",
    "\n",
    "for reaction_index in range(df.shape[0]):\n",
    "    if reaction_index % 400 == 0:\n",
    "        print(reaction_index)\n",
    "    r = df['reactants_mapped'].values[reaction_index]\n",
    "    r_center = df['core_index_atom'].values[reaction_index].split('>')\n",
    "    for ri_index in range(len(r.split('.'))):\n",
    "        ri = r.split('.')[ri_index]\n",
    "        ri_afm, ri_adj, ri_dist = load_data_from_smiles(ri)\n",
    "        #print(ri, ri_afm)\n",
    "        #print(ri_afm.shape)\n",
    "        ri_list.append(ri)\n",
    "        ri_afm_list.append(ri_afm)\n",
    "        ri_adj_list.append(ri_adj)\n",
    "        ri_dist_list.append(ri_dist)\n",
    "        ri_center_index = [0] + [int(k) + 1 for k in r_center[ri_index].split('.')] #dummy node also count as reaction center\n",
    "        ri_center_list.append(np.array(ri_center_index))\n",
    "        \n",
    "        reaction_index_list.append(int(reaction_index))\n",
    "        molecule_index_list.append(int(ri_index))\n",
    "        yield_list.append(df['yield'].values[reaction_index])\n",
    "    r_dic = {'reactants': ri_list, 'reactant_afm': ri_afm_list, 'reactant_adj': ri_adj_list, 'reactant_dist': ri_dist_list, 'reaction_index':reaction_index_list, 'molecule_index': molecule_index_list, 'center_index': ri_center_list, 'yield': yield_list}\n",
    "     \n",
    "print(len(ri_list))\n",
    "with open('BH_reactants_feats.pkl', 'wb') as f:\n",
    "    pickle.dump(r_dic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "400\n",
      "800\n",
      "1200\n",
      "1600\n",
      "2000\n",
      "2400\n",
      "2800\n",
      "3200\n",
      "3600\n",
      "11865\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./BH_processed.csv')\n",
    "r_dic = []\n",
    "ri_list = []\n",
    "ri_afm_list = []\n",
    "ri_adj_list = []\n",
    "ri_dist_list = []\n",
    "reaction_index_list = []\n",
    "molecule_index_list = []\n",
    "yield_list = []\n",
    "\n",
    "for reaction_index in range(df.shape[0]):\n",
    "    if reaction_index % 400 == 0:\n",
    "        print(reaction_index)\n",
    "    r = df['reagents'].values[reaction_index]\n",
    "    for ri_index in range(len(r.split('.'))):\n",
    "        ri = r.split('.')[ri_index]\n",
    "        ri_afm, ri_adj, ri_dist = load_data_from_smiles(ri)\n",
    "        ri_list.append(ri)\n",
    "        ri_afm_list.append(ri_afm)\n",
    "        ri_adj_list.append(ri_adj)\n",
    "        ri_dist_list.append(ri_dist)\n",
    "        \n",
    "        reaction_index_list.append(int(reaction_index))\n",
    "        molecule_index_list.append(int(ri_index))\n",
    "        yield_list.append(df['yield'].values[reaction_index])\n",
    "    r_dic = {'reagents': ri_list, 'reagent_afm': ri_afm_list, 'reagent_adj': ri_adj_list, 'reagent_dist': ri_dist_list, 'reaction_index':reaction_index_list, 'molecule_index': molecule_index_list, 'yield': yield_list}\n",
    "print(len(ri_list))  \n",
    "with open('BH_reagents_feats.pkl', 'wb') as f:\n",
    "    pickle.dump(r_dic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "3955\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./BH_processed.csv')\n",
    "r_dic = []\n",
    "ri_list = []\n",
    "ri_afm_list = []\n",
    "ri_adj_list = []\n",
    "ri_dist_list = []\n",
    "reaction_index_list = []\n",
    "molecule_index_list = []\n",
    "yield_list = []\n",
    "\n",
    "for reaction_index in range(df.shape[0]):\n",
    "    if reaction_index % 1000 == 0:\n",
    "        print(reaction_index)\n",
    "    r = df['products'].values[reaction_index]\n",
    "    for ri_index in range(len(r.split('.'))):\n",
    "        ri = r.split('.')[ri_index]\n",
    "        ri_afm, ri_adj, ri_dist = load_data_from_smiles(ri)\n",
    "        ri_list.append(ri)\n",
    "        ri_afm_list.append(ri_afm)\n",
    "        ri_adj_list.append(ri_adj)\n",
    "        ri_dist_list.append(ri_dist)\n",
    "        \n",
    "        reaction_index_list.append(int(reaction_index))\n",
    "        molecule_index_list.append(int(ri_index))\n",
    "        yield_list.append(df['yield'].values[reaction_index])\n",
    "    r_dic = {'products': ri_list, 'product_afm': ri_afm_list, 'product_adj': ri_adj_list, 'product_dist': ri_dist_list, 'reaction_index':reaction_index_list, 'molecule_index': molecule_index_list, 'yield': yield_list}\n",
    "print(len(ri_list))    \n",
    "with open('BH_products_feats.pkl', 'wb') as f:\n",
    "    pickle.dump(r_dic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 29)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ri_afm_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_array(array, shape, dtype=np.float32):\n",
    "    \"\"\"Pad a 2-dimensional array with zeros.\n",
    "\n",
    "    Args:\n",
    "        array (ndarray): A 2-dimensional array to be padded.\n",
    "        shape (tuple[int]): The desired shape of the padded array.\n",
    "        dtype (data-type): The desired data-type for the array.\n",
    "\n",
    "    Returns:\n",
    "        A 2-dimensional array of the given shape padded with zeros.\n",
    "    \"\"\"\n",
    "    padded_array = np.zeros(shape, dtype=dtype)\n",
    "    padded_array[:array.shape[0], :array.shape[1]] = array\n",
    "    return padded_array\n",
    "\n",
    "\n",
    "def mol_collate_func(batch_adjacency_matrix, batch_node_matrix, batch_distance_matrix):\n",
    "    \"\"\"Create a padded batch of molecule features.\n",
    "\n",
    "    Args:\n",
    "        batch (list[Molecule]): A batch of raw molecules.\n",
    "\n",
    "    Returns:\n",
    "        A list of FloatTensors with padded molecule features:\n",
    "        adjacency matrices, node features, distance matrices, and labels.\n",
    "    \"\"\"\n",
    "    adjacency_list, distance_list, features_list = [], [], []\n",
    "\n",
    "    max_size = 0\n",
    "    for i in range(batch_adjacency_matrix.shape[0]):\n",
    "        molecule_adjacency_matrix = batch_adjacency_matrix[i]\n",
    "        molecule_node_matrix = batch_node_matrix[i]\n",
    "        molecule_distance_matrix = batch_distance_matrix[i]\n",
    "        \n",
    "        if molecule_adjacency_matrix.shape[0] > max_size:\n",
    "            max_size = molecule_adjacency_matrix.shape[0]\n",
    "            \n",
    "    #print(max_size)\n",
    "    for i in range(batch_adjacency_matrix.shape[0]):\n",
    "        adjacency_list.append(pad_array(batch_adjacency_matrix[i], (max_size, max_size)))\n",
    "        distance_list.append(pad_array(batch_distance_matrix[i], (max_size, max_size)))\n",
    "        features_list.append(pad_array(batch_node_matrix[i], (max_size, batch_node_matrix[i].shape[1])))\n",
    "\n",
    "    return [FloatTensor(features) for features in (adjacency_list, features_list, distance_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataloader\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class Graph_DataLoader(Dataset):\n",
    "    def __init__(self, data, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return idx, self.data[idx,5].__float__()/100 # reactants, yield\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated model parameter name\n",
      "encoder.layers.0.self_attn.linears.0.weight <built-in method size of Parameter object at 0x2b77c95a7818>\n",
      "encoder.layers.0.self_attn.linears.0.bias <built-in method size of Parameter object at 0x2b77c95a7868>\n",
      "encoder.layers.0.self_attn.linears.1.weight <built-in method size of Parameter object at 0x2b77c95a78b8>\n",
      "encoder.layers.0.self_attn.linears.1.bias <built-in method size of Parameter object at 0x2b77c95a7908>\n",
      "encoder.layers.0.self_attn.linears.2.weight <built-in method size of Parameter object at 0x2b77c95a7958>\n",
      "encoder.layers.0.self_attn.linears.2.bias <built-in method size of Parameter object at 0x2b77c95a79a8>\n",
      "encoder.layers.0.self_attn.linears.3.weight <built-in method size of Parameter object at 0x2b77c95a79f8>\n",
      "encoder.layers.0.self_attn.linears.3.bias <built-in method size of Parameter object at 0x2b77c95a7a48>\n",
      "encoder.layers.0.feed_forward.linears.0.weight <built-in method size of Parameter object at 0x2b77c95a7a98>\n",
      "encoder.layers.0.feed_forward.linears.0.bias <built-in method size of Parameter object at 0x2b77c95a7ae8>\n",
      "encoder.layers.0.sublayer.0.norm.a_2 <built-in method size of Parameter object at 0x2b77c95a7b38>\n",
      "encoder.layers.0.sublayer.0.norm.b_2 <built-in method size of Parameter object at 0x2b77c95a7b88>\n",
      "encoder.layers.0.sublayer.1.norm.a_2 <built-in method size of Parameter object at 0x2b77c95a7bd8>\n",
      "encoder.layers.0.sublayer.1.norm.b_2 <built-in method size of Parameter object at 0x2b77c95a7c28>\n",
      "encoder.layers.1.self_attn.linears.0.weight <built-in method size of Parameter object at 0x2b77c95a7c78>\n",
      "encoder.layers.1.self_attn.linears.0.bias <built-in method size of Parameter object at 0x2b77c95a7cc8>\n",
      "encoder.layers.1.self_attn.linears.1.weight <built-in method size of Parameter object at 0x2b77c95a7d18>\n",
      "encoder.layers.1.self_attn.linears.1.bias <built-in method size of Parameter object at 0x2b77c95a7d68>\n",
      "encoder.layers.1.self_attn.linears.2.weight <built-in method size of Parameter object at 0x2b77c95a7db8>\n",
      "encoder.layers.1.self_attn.linears.2.bias <built-in method size of Parameter object at 0x2b77c95a7e08>\n",
      "encoder.layers.1.self_attn.linears.3.weight <built-in method size of Parameter object at 0x2b77c95a7e58>\n",
      "encoder.layers.1.self_attn.linears.3.bias <built-in method size of Parameter object at 0x2b77c95a7ea8>\n",
      "encoder.layers.1.feed_forward.linears.0.weight <built-in method size of Parameter object at 0x2b77c95a7ef8>\n",
      "encoder.layers.1.feed_forward.linears.0.bias <built-in method size of Parameter object at 0x2b77c95a7f48>\n",
      "encoder.layers.1.sublayer.0.norm.a_2 <built-in method size of Parameter object at 0x2b77c95a7f98>\n",
      "encoder.layers.1.sublayer.0.norm.b_2 <built-in method size of Parameter object at 0x2b77d3f51048>\n",
      "encoder.layers.1.sublayer.1.norm.a_2 <built-in method size of Parameter object at 0x2b77d3f51098>\n",
      "encoder.layers.1.sublayer.1.norm.b_2 <built-in method size of Parameter object at 0x2b77d3f510e8>\n",
      "encoder.layers.2.self_attn.linears.0.weight <built-in method size of Parameter object at 0x2b77d3f51138>\n",
      "encoder.layers.2.self_attn.linears.0.bias <built-in method size of Parameter object at 0x2b77d3f51188>\n",
      "encoder.layers.2.self_attn.linears.1.weight <built-in method size of Parameter object at 0x2b77d3f511d8>\n",
      "encoder.layers.2.self_attn.linears.1.bias <built-in method size of Parameter object at 0x2b77d3f51228>\n",
      "encoder.layers.2.self_attn.linears.2.weight <built-in method size of Parameter object at 0x2b77d3f51278>\n",
      "encoder.layers.2.self_attn.linears.2.bias <built-in method size of Parameter object at 0x2b77d3f512c8>\n",
      "encoder.layers.2.self_attn.linears.3.weight <built-in method size of Parameter object at 0x2b77d3f51318>\n",
      "encoder.layers.2.self_attn.linears.3.bias <built-in method size of Parameter object at 0x2b77d3f51368>\n",
      "encoder.layers.2.feed_forward.linears.0.weight <built-in method size of Parameter object at 0x2b77d3f513b8>\n",
      "encoder.layers.2.feed_forward.linears.0.bias <built-in method size of Parameter object at 0x2b77d3f51408>\n",
      "encoder.layers.2.sublayer.0.norm.a_2 <built-in method size of Parameter object at 0x2b77d3f51458>\n",
      "encoder.layers.2.sublayer.0.norm.b_2 <built-in method size of Parameter object at 0x2b77d3f514a8>\n",
      "encoder.layers.2.sublayer.1.norm.a_2 <built-in method size of Parameter object at 0x2b77d3f514f8>\n",
      "encoder.layers.2.sublayer.1.norm.b_2 <built-in method size of Parameter object at 0x2b77d3f51548>\n",
      "encoder.layers.3.self_attn.linears.0.weight <built-in method size of Parameter object at 0x2b77d3f51598>\n",
      "encoder.layers.3.self_attn.linears.0.bias <built-in method size of Parameter object at 0x2b77d3f515e8>\n",
      "encoder.layers.3.self_attn.linears.1.weight <built-in method size of Parameter object at 0x2b77d3f51638>\n",
      "encoder.layers.3.self_attn.linears.1.bias <built-in method size of Parameter object at 0x2b77d3f51688>\n",
      "encoder.layers.3.self_attn.linears.2.weight <built-in method size of Parameter object at 0x2b77d3f516d8>\n",
      "encoder.layers.3.self_attn.linears.2.bias <built-in method size of Parameter object at 0x2b77d3f51728>\n",
      "encoder.layers.3.self_attn.linears.3.weight <built-in method size of Parameter object at 0x2b77d3f51778>\n",
      "encoder.layers.3.self_attn.linears.3.bias <built-in method size of Parameter object at 0x2b77d3f517c8>\n",
      "encoder.layers.3.feed_forward.linears.0.weight <built-in method size of Parameter object at 0x2b77d3f51818>\n",
      "encoder.layers.3.feed_forward.linears.0.bias <built-in method size of Parameter object at 0x2b77d3f51868>\n",
      "encoder.layers.3.sublayer.0.norm.a_2 <built-in method size of Parameter object at 0x2b77d3f518b8>\n",
      "encoder.layers.3.sublayer.0.norm.b_2 <built-in method size of Parameter object at 0x2b77d3f51908>\n",
      "encoder.layers.3.sublayer.1.norm.a_2 <built-in method size of Parameter object at 0x2b77d3f51958>\n",
      "encoder.layers.3.sublayer.1.norm.b_2 <built-in method size of Parameter object at 0x2b77d3f519a8>\n",
      "encoder.layers.4.self_attn.linears.0.weight <built-in method size of Parameter object at 0x2b77d3f519f8>\n",
      "encoder.layers.4.self_attn.linears.0.bias <built-in method size of Parameter object at 0x2b77d3f51a48>\n",
      "encoder.layers.4.self_attn.linears.1.weight <built-in method size of Parameter object at 0x2b77d3f51a98>\n",
      "encoder.layers.4.self_attn.linears.1.bias <built-in method size of Parameter object at 0x2b77d3f51ae8>\n",
      "encoder.layers.4.self_attn.linears.2.weight <built-in method size of Parameter object at 0x2b77d3f51b38>\n",
      "encoder.layers.4.self_attn.linears.2.bias <built-in method size of Parameter object at 0x2b77d3f51b88>\n",
      "encoder.layers.4.self_attn.linears.3.weight <built-in method size of Parameter object at 0x2b77d3f51bd8>\n",
      "encoder.layers.4.self_attn.linears.3.bias <built-in method size of Parameter object at 0x2b77d3f51c28>\n",
      "encoder.layers.4.feed_forward.linears.0.weight <built-in method size of Parameter object at 0x2b77d3f51c78>\n",
      "encoder.layers.4.feed_forward.linears.0.bias <built-in method size of Parameter object at 0x2b77d3f51cc8>\n",
      "encoder.layers.4.sublayer.0.norm.a_2 <built-in method size of Parameter object at 0x2b77d3f51d18>\n",
      "encoder.layers.4.sublayer.0.norm.b_2 <built-in method size of Parameter object at 0x2b77d3f51d68>\n",
      "encoder.layers.4.sublayer.1.norm.a_2 <built-in method size of Parameter object at 0x2b77d3f51db8>\n",
      "encoder.layers.4.sublayer.1.norm.b_2 <built-in method size of Parameter object at 0x2b77d3f51e08>\n",
      "encoder.layers.5.self_attn.linears.0.weight <built-in method size of Parameter object at 0x2b77d3f51e58>\n",
      "encoder.layers.5.self_attn.linears.0.bias <built-in method size of Parameter object at 0x2b77d3f51ea8>\n",
      "encoder.layers.5.self_attn.linears.1.weight <built-in method size of Parameter object at 0x2b77d3f51ef8>\n",
      "encoder.layers.5.self_attn.linears.1.bias <built-in method size of Parameter object at 0x2b77d3f51f48>\n",
      "encoder.layers.5.self_attn.linears.2.weight <built-in method size of Parameter object at 0x2b77d3f51f98>\n",
      "encoder.layers.5.self_attn.linears.2.bias <built-in method size of Parameter object at 0x2b77d3f8b048>\n",
      "encoder.layers.5.self_attn.linears.3.weight <built-in method size of Parameter object at 0x2b77d3f8b098>\n",
      "encoder.layers.5.self_attn.linears.3.bias <built-in method size of Parameter object at 0x2b77d3f8b0e8>\n",
      "encoder.layers.5.feed_forward.linears.0.weight <built-in method size of Parameter object at 0x2b77d3f8b138>\n",
      "encoder.layers.5.feed_forward.linears.0.bias <built-in method size of Parameter object at 0x2b77d3f8b188>\n",
      "encoder.layers.5.sublayer.0.norm.a_2 <built-in method size of Parameter object at 0x2b77d3f8b1d8>\n",
      "encoder.layers.5.sublayer.0.norm.b_2 <built-in method size of Parameter object at 0x2b77d3f8b228>\n",
      "encoder.layers.5.sublayer.1.norm.a_2 <built-in method size of Parameter object at 0x2b77d3f8b278>\n",
      "encoder.layers.5.sublayer.1.norm.b_2 <built-in method size of Parameter object at 0x2b77d3f8b2c8>\n",
      "encoder.norm.a_2 <built-in method size of Parameter object at 0x2b77c95aff48>\n",
      "encoder.norm.b_2 <built-in method size of Parameter object at 0x2b77c95afef8>\n",
      "src_embed.lut.weight <built-in method size of Parameter object at 0x2b77c95a77c8>\n",
      "src_embed.lut.bias <built-in method size of Parameter object at 0x2b77c95a7778>\n",
      "generator.proj.weight <built-in method size of Parameter object at 0x2b77c95a7728>\n",
      "generator.proj.bias <built-in method size of Parameter object at 0x2b77c95a76d8>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "os.chdir('src')\n",
    "from transformer import make_model\n",
    "\n",
    "num_layers_to_keep = 6\n",
    "model_params = {\n",
    "    'd_atom': 28,\n",
    "    'd_model': 1024,\n",
    "    'N': num_layers_to_keep,\n",
    "    'h': 16,\n",
    "    'N_dense': 1,\n",
    "    'lambda_attention': 0.33, \n",
    "    'lambda_distance': 0.33,\n",
    "    'leaky_relu_slope': 0.1, \n",
    "    'dense_output_nonlinearity': 'relu', \n",
    "    'distance_matrix_kernel': 'exp', \n",
    "    'dropout': 0.0,\n",
    "    'aggregation_type': 'mean'\n",
    "}\n",
    "\n",
    "pretrained_name = '../pretrained_weights.pt'  # This file should be downloaded first (See README.md).\n",
    "pretrained_state_dict = torch.load(pretrained_name)\n",
    "\n",
    "# Define the layers to keep\n",
    "layers_to_keep = [\n",
    "    \"src_embed.lut.weight\",  # these are additional the layers to keep\n",
    "    \"src_embed.lut.bias\",\n",
    "    \"generator.proj.weight\",\n",
    "    \"generator.proj.bias\",\n",
    "    *[f\"encoder.layer.{i}.\" for i in range(num_layers_to_keep)]  # Keep the first 6 self-attention layers\n",
    "]\n",
    "model = make_model(**model_params)\n",
    "model_state_dict = model.state_dict()\n",
    "\n",
    "# Filter out the parameters corresponding to the specified layers\n",
    "filtered_state_dict = {k: v for k, v in pretrained_state_dict.items() if any(layer in k for layer in layers_to_keep)}\n",
    "for name, param in filtered_state_dict.items():\n",
    "    if 'generator' in name:\n",
    "         continue\n",
    "    if isinstance(param, torch.nn.Parameter):\n",
    "        param = param.data\n",
    "    model_state_dict[name].copy_(param)\n",
    "print('Updated model parameter name')\n",
    "for name, param_i in model.named_parameters():\n",
    "    print(name, param_i.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "\"\"\"\n",
    "Dataloader\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class Graph_DataLoader(Dataset):\n",
    "    def __init__(self, data, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return idx, self.data[idx,5].__float__()/100 #return reaction indices and yields\n",
    "    \n",
    "    \n",
    "def get_reactant_batch(r_feats, set_index, batch_index):\n",
    "    batch_index_indeed = set_index[batch_index] #the indices of batch_reactions in original dataset(3955)\n",
    "    temp = torch.Tensor([])\n",
    "    for i in range(len(batch_index)):\n",
    "        temp = torch.cat((temp, torch.where(torch.Tensor(r_feats['reaction_index']) == batch_index_indeed[i])[0]), dim=0) # index is reactant index\n",
    "    index = [int(i.item()) for i in temp] #indices of molecules in batch_reactions\n",
    "\n",
    "    r_batch_adjacency_matrix = np.array(r_feats['reactant_adj'])[index] \n",
    "    r_batch_node_features = np.array(r_feats['reactant_afm'])[index]\n",
    "    r_batch_distance_matrix = np.array(r_feats['reactant_dist'])[index]\n",
    "    r_batch_center_index = np.array(r_feats['center_index'])[index]\n",
    "    r_batch_index = np.array(r_feats['reaction_index'])[index]\n",
    "\n",
    "    r_batch_adjacency_matrix, r_batch_node_features, r_batch_distance_matrix = mol_collate_func(r_batch_adjacency_matrix, r_batch_node_features, r_batch_distance_matrix) #padded function\n",
    "    r_batch_mask = torch.sum(torch.abs(r_batch_node_features), dim=-1) != 0    \n",
    "\n",
    "    return r_batch_adjacency_matrix, r_batch_node_features, r_batch_distance_matrix, r_batch_mask, r_batch_center_index, r_batch_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import pandas as pd\n",
    "df = pd.read_csv('../BH_processed.csv')\n",
    "\n",
    "with open('../BH_reactant_feats.pkl', 'rb') as f:\n",
    "    reactant_features = pickle.load(f)\n",
    "\n",
    "data_dir = '/fs/ess/PCON0041/xiaohu/Yield_Predicion_M/Data/preprocessed_datasets/BH/BH_processed.csv'\n",
    "with open('../train_test_idxs.pickle', 'rb') as handle:\n",
    "    idx_dict = pickle.load(handle)\n",
    "        \n",
    "train_index = idx_dict['train_idx'][1]\n",
    "test_index = idx_dict['test_idx'][1]\n",
    "valid_index = train_index[int(0.9*len(train_index)):]\n",
    "train_index = train_index[0:int(0.9*len(train_index))]\n",
    "\n",
    "testset = Graph_DataLoader(df.loc[test_index].values, data_dir)\n",
    "test_loader = DataLoader(testset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/PCON0041/xiaohu/anaconda3/envs/rxnfp/lib/python3.6/site-packages/ipykernel_launcher.py:30: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/users/PCON0041/xiaohu/anaconda3/envs/rxnfp/lib/python3.6/site-packages/ipykernel_launcher.py:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/users/PCON0041/xiaohu/anaconda3/envs/rxnfp/lib/python3.6/site-packages/ipykernel_launcher.py:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/users/PCON0041/xiaohu/anaconda3/envs/rxnfp/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n"
     ]
    }
   ],
   "source": [
    "for iter, (batch_index, batch_targets) in enumerate(test_loader): #batch_index is reaction index\n",
    "    r_batch_adjacency_matrix, r_batch_node_features, r_batch_distance_matrix, r_batch_mask, r_batch_center_index, r_batch_index = get_reactant_batch(reactant_features, test_index, batch_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "torch.Size([0]) torch.Size([0]) torch.Size([0]) torch.Size([3]) (0, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/PCON0041/xiaohu/anaconda3/envs/rxnfp/lib/python3.6/site-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/users/PCON0041/xiaohu/anaconda3/envs/rxnfp/lib/python3.6/site-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/users/PCON0041/xiaohu/anaconda3/envs/rxnfp/lib/python3.6/site-packages/ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7804e9d49b97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_adjacency_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_node_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_distance_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_center_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_node_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_adjacency_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_distance_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "    #print(reactant_features['reaction_index'][test_index].shape)\n",
    "    total_test_reaction_index = torch.Tensor(reactant_features['reaction_index'])[test_index]\n",
    "    #print(total_test_features.shape)\n",
    "    temp = torch.Tensor([])\n",
    "    for i in range(len(batch_index)):\n",
    "        temp = torch.cat((temp, torch.where(total_test_reaction_index == batch_index[i])[0]), dim=0) # index is reactant index\n",
    "    index = [int(i.item()) for i in temp]\n",
    "\n",
    "    batch_adjacency_matrix = np.array(reactant_features['reactant_adj'])[test_index][index] \n",
    "    batch_node_features = np.array(reactant_features['reactant_afm'])[test_index][index]\n",
    "    batch_distance_matrix = np.array(reactant_features['reactant_dist'])[test_index][index]\n",
    "    batch_center_index = np.array(reactant_features['center_index'])[test_index][index]\n",
    "    print(batch_center_index)\n",
    "    batch_adjacency_matrix, batch_node_features, batch_distance_matrix = mol_collate_func(batch_adjacency_matrix, batch_node_features, batch_distance_matrix)\n",
    "    batch_mask = torch.sum(torch.abs(batch_node_features), dim=-1) != 0 \n",
    "  \n",
    "    print(batch_adjacency_matrix.shape, batch_node_features.shape, batch_distance_matrix.shape, batch_targets.shape, batch_center_index.shape)\n",
    "    output = model(batch_node_features.to(device), batch_mask.to(device), batch_adjacency_matrix.to(device), batch_distance_matrix.to(device), None)\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "mol = MolFromSmiles(smiles[0])\n",
    "mol = Chem.AddHs(mol)\n",
    "AllChem.EmbedMolecule(mol, maxAttempts=5000)\n",
    "AllChem.UFFOptimizeMolecule(mol)\n",
    "mol = Chem.RemoveHs(mol)\n",
    "print(len(mol.GetAtoms()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'C', 'F', 'F', 'C', 'C', 'C', 'C', 'Cl', 'C', 'C', 'N', 'C', 'C', 'C', 'C', 'C', 'C', 'C']\n"
     ]
    }
   ],
   "source": [
    "element = [atom.GetSymbol() for atom in mol.GetAtoms()]\n",
    "print(element)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      F    C    F    F    C    C    C    C   Cl    C    C    N    C    C    C  \\\n",
      "F   1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "C   1.0  1.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "F   0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "F   0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "C   0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
      "C   0.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "C   0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "C   0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "Cl  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "C   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0   \n",
      "C   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0   \n",
      "N   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0   \n",
      "C   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0   \n",
      "C   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0   \n",
      "C   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0   \n",
      "C   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "C   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "C   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "C   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
      "\n",
      "      C    C    C    C  \n",
      "F   0.0  0.0  0.0  0.0  \n",
      "C   0.0  0.0  0.0  0.0  \n",
      "F   0.0  0.0  0.0  0.0  \n",
      "F   0.0  0.0  0.0  0.0  \n",
      "C   0.0  0.0  0.0  0.0  \n",
      "C   0.0  0.0  0.0  0.0  \n",
      "C   0.0  0.0  0.0  0.0  \n",
      "C   0.0  0.0  0.0  0.0  \n",
      "Cl  0.0  0.0  0.0  0.0  \n",
      "C   0.0  0.0  0.0  0.0  \n",
      "C   0.0  0.0  0.0  0.0  \n",
      "N   0.0  0.0  0.0  0.0  \n",
      "C   0.0  0.0  0.0  1.0  \n",
      "C   0.0  0.0  0.0  0.0  \n",
      "C   1.0  0.0  0.0  0.0  \n",
      "C   1.0  1.0  1.0  0.0  \n",
      "C   1.0  1.0  0.0  0.0  \n",
      "C   1.0  0.0  1.0  1.0  \n",
      "C   0.0  0.0  1.0  1.0  \n"
     ]
    }
   ],
   "source": [
    "['F', 'C', 'F', 'F', 'C', 'C', 'C', 'C', 'Cl', 'C', 'C', 'N', 'C', 'C', 'C', 'C', 'C', 'C', 'C']\n",
    "\n",
    "df_e = pd.DataFrame(x[0][1][1:,1:], index=element,  columns=element)\n",
    "print(df_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/PCON0041/xiaohu/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted tensor1: tensor([1, 1, 3, 4, 5])\n",
      "Corresponding sorted tensor2: tensor([2, 8, 9, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example tensors\n",
    "tensor1 = torch.tensor([3, 1, 4, 1, 5])\n",
    "tensor2 = torch.tensor([9, 2, 5, 8, 3])\n",
    "\n",
    "# Sort tensor1 based on the values in tensor2\n",
    "sorted_tensor1, indices = torch.sort(tensor1)\n",
    "sorted_tensor2 = tensor2[indices]\n",
    "\n",
    "print(\"Sorted tensor1:\", sorted_tensor1)\n",
    "print(\"Corresponding sorted tensor2:\", sorted_tensor2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor([ 367., 2061., 2829.,  583., 2242., 1751., 2143., 1497., 2631.,  700.,\n",
    "        3310., 2754., 3321.,  603., 3361., 2932.,   47., 1383.,  821., 2349.,\n",
    "        3717., 3277., 2084., 3177.,  334., 2552., 1090., 1972., 3162., 3326.,\n",
    "        2628., 1992.])\n",
    "\n",
    "tensor([  47.,  334.,  367.,  583.,  603.,  700.,  821., 1090., 1383., 1497.,\n",
    "        1751., 1972., 1992., 2061., 2084., 2143., 2242., 2349., 2552., 2628.,\n",
    "        2631., 2754., 2829., 2932., 3162., 3177., 3277., 3310., 3321., 3326.,\n",
    "        3361., 3717.], device='cuda:0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rxnfp",
   "language": "python",
   "name": "rxnfp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
